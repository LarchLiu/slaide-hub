---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG: 一种GraphRAG替代方案"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.2|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["哈喽，大家好！","今天咱们聊一个新东西","关于生成式 AI 加“外挂”的升级版","这个外挂叫做 LightRAG！"],"en":["Hello everyone!","Today we're talking about something new,","an upgraded version of generative AI with an 'add-on',","and this add-on is called LightRAG!"]}}
---

# LightRAG: RAG的升级与实践

## 一种新的检索增强生成框架

---
page: 2

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你可能听过 RAG","就是“检索增强生成”","让大模型先搜资料再回答","这样答案更靠谱、准确"],"en":["You might have heard of RAG,","which stands for Retrieval-Augmented Generation.","It allows large language models to retrieve external knowledge before generating answers,","improving the accuracy and timeliness of responses."]}}
---

# 理解 RAG

- **RAG** (Retrieval-Augmented Generation) 检索增强生成
- 让大型语言模型 (LLM) 在生成回答前**检索外部知识**
- 提升回答的**准确性**和**时效性**

---
page: 3

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 把 RAG 玩出了新花样","而且又快又省钱！","我写了篇文章深入聊它","接下来就给你好好讲讲"],"en":["LightRAG brings new advancements to RAG,","and it's faster and more cost-effective!","I've written an article discussing it in depth,","and next, I'll tell you all about it."]}}
---

# LightRAG - RAG新突破

- **LightRAG**: 一种先进、高成本效益的 RAG 框架
- 结合**知识图谱**与**向量检索**
- 带来更准确、更具上下文感知的文档交互
- 相较传统 RAG **更快**、**更省钱**

---
page: 4

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["传统的 RAG 有个问题","它找到文字片段","但片段间的“关系”可能看不到","就像看一堆乐高积木","不知道它们能不能拼成房子"],"en":["Traditional RAG has a challenge:","it splits documents into isolated segments,","ignoring the contextual relationships between them.","This makes it difficult to accurately answer complex questions,","like looking at a pile of scattered bricks, not knowing how to build a whole structure."]}}
---

# 传统 RAG 的挑战

- 传统 RAG 将文档切分**孤立片段**
- 忽略片段间的**上下文关系**
- 难以准确回答**复杂问题**
- 像看一堆零散的积木，不知道如何构建整体

---
page: 5

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 厉害在这儿了","它不只切文档","还会构建“知识图谱”","知识图谱像张巨大关系网","点是概念，连线是关系","LightRAG 能建立“实体-关系对”","保留信息间的上下文联系"],"en":["This is where LightRAG is powerful.","It doesn't just split documents;","it builds a 'knowledge graph'.","A knowledge graph is like a vast network of relationships,","where nodes are concepts and edges are relationships.","LightRAG can establish 'Entity-Relationship Pairs',","preserving the contextual connections between information."]}}
---

# LightRAG 的核心: 知识图谱

- LightRAG 构建**知识图谱**来解决上下文问题
- 知识图谱映射数据中的**实体**及其**关系**
- 建立**实体-关系对 (Entity-Relationship Pairs)**
- 保留文档片段间的**上下文联系**

---
page: 6

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["文章提到微软的 GraphRAG","它也用知识图谱增强 RAG","想法有点像"],"en":["The article mentions Microsoft's GraphRAG,","which also uses knowledge graphs to enhance RAG.","The idea is somewhat similar."]},"click1":{"zh_CN":["但 LightRAG 更吸引人：","速度更快，成本更低","最棒是能“增量更新”！"],"en":["But LightRAG is more appealing:","it's faster and more economical,","and the best part is it supports incremental updates!"]}}
---

# LightRAG vs GraphRAG

- **GraphRAG (Microsoft)**: 也使用知识图谱增强 RAG

<div v-click="1">

- **LightRAG 的优势**: 
  - **更快**, **更经济**
  - 支持**增量更新**，无需重建整个图谱

</div>

---
page: 7

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["这一点非常重要","像 GraphRAG 如果数据更新","可能得推倒重建知识图谱","耗费大量资源和钱"],"en":["This point is very important.","With GraphRAG, if data is updated,","you might have to rebuild the entire knowledge graph,","which is resource-intensive and costly."]},"click1":{"zh_CN":["LightRAG 聪明多了","只更新变化的部分，像打补丁"],"en":["LightRAG is much smarter.","It only updates the parts that have changed, like applying patches."]},"click2":{"zh_CN":["大大降低成本和时间"],"en":["Significantly reducing costs and time."]}}
---

# 增量更新的重要性

- GraphRAG 数据更新需**重建整个图谱**，资源密集，成本高

<div v-click="1">

- LightRAG 采用**增量更新系统**
- **只更新变化的部分**，快速添加新数据

</div>

<div v-click="2">

- 大幅**降低成本和时间**，应对信息快速变化领域

</div>

---
page: 8

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["而且 LightRAG 检索方式很有意思","用了“双层检索”"],"en":["Also, LightRAG's retrieval method is quite interesting.","It uses 'Dual-Level Retrieval'."]},"click1":{"zh_CN":["低层检索"],"en":["Low-Level Retrieval"]},"click2":{"zh_CN":["高层检索"],"en":["High-Level Retrieval"]}}
---

# 双层检索 (Dual-Level Retrieval)

LightRAG 独特的检索方式，结合：

<div v-click="1">

1. **低层检索 (Low-Level)**

</div>

<div v-click="2">

2. **高层检索 (High-Level)**

</div>

---
page: 9

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["一层是“低层检索”"],"en":["One layer is 'Low-Level Retrieval'."]},"click1":{"zh_CN":["看知识图谱里实体附近的节点关系","像放大镜看细节"],"en":["It focuses on nodes near entities in the knowledge graph,","like using a magnifying glass to see details."]},"click2":{"zh_CN":["回答非常具体、精准的问题"],"en":["It answers specific, precise questions."]},"click3":{"zh_CN":["比如某个电动车的统计数据"],"en":["For example, statistical data or regulations about a specific electric vehicle."]}}
---

# 低层检索 (Low-Level Retrieval)

<div v-click="1">

- 关注知识图谱中实体**附近的节点**
- 像**放大镜**看细节

</div>

<div v-click="2">

- 回答**具体、精准**的问题

</div>

<div v-click="3">

- 例如：关于某个电动车的统计数据或法规

</div>

---
page: 10

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["另一层是“高层检索”"],"en":["The other layer is 'High-Level Retrieval'."]},"click1":{"zh_CN":["看整个图谱的宏观联系和主题","像从高空俯瞰"],"en":["It identifies the overall themes and connections in the entire graph,","like taking a bird's-eye view."]},"click2":{"zh_CN":["捕捉更广泛的上下文和主题"],"en":["It captures broader context and themes."]},"click3":{"zh_CN":["比如电动车对环境的影响趋势"],"en":["For example, trends in the environmental impact of electric vehicles or future urban transportation."]}}
---

# 高层检索 (High-Level Retrieval)

<div v-click="1">

- 识别整个图谱的**宏观主题**和**联系**
- 像**从高空俯瞰**

</div>

<div v-click="2">

- 捕捉**更广泛的上下文**和**主题**

</div>

<div v-click="3">

- 例如：电动车对环境影响的趋势或未来城市交通

</div>

---
page: 11

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["把这两层结合（“混合模式”）"],"en":["Combining these two layers ('Hybrid Mode')"]},"click1":{"zh_CN":["给你一个既有细节又有大局观的回答"],"en":["provides an answer with both detail and a global perspective."]},"click2":{"zh_CN":["这是让 RAG 系统更“聪明”的一大步","更全面"],"en":["This makes the RAG system 'smarter' and more comprehensive.","It's a big step forward in enhancing RAG."]}}
---

# 混合模式与优势

- **混合模式 (Hybrid Mode)**: 结合低层和高层检索

<div v-click="1">

- 提供既有**细节**又有**全局观**的回答

</div>

<div v-click="2">

- 让 RAG 系统更**“聪明”**，更全面
- 这是增强 RAG 的一大步

</div>

---
page: 12

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 结合知识图谱"],"en":["LightRAG combines knowledge graphs"]},"click1":{"zh_CN":["也没丢掉传统的向量搜索","它能理解概念关系","也能快速找到语义相似内容"],"en":["while also incorporating traditional vector retrieval.","It understands conceptual relationships","and quickly finds semantically similar content."]},"click2":{"zh_CN":["再加上去重功能","信息准确、有上下文，不重复","非常高效"],"en":["Plus, it has a deduplication feature,","ensuring information is accurate, contextual, and non-redundant,","making it highly efficient."]}}
---

# 知识图谱 + 向量检索

- LightRAG 结合**知识图谱**与**向量检索**

<div v-click="1">

- 理解概念关系，快速找到语义相似内容

</div>

<div v-click="2">

- 具备**去重功能 (Deduplication)**
- 确保信息**准确**、**有上下文**、**不重复**

</div>

---
page: 13

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["我的测试中，LightRAG 表现印象深刻"],"en":["In my tests, LightRAG showed impressive performance."]},"click1":{"zh_CN":["准确性和速度都比老旧 RAG 模型有提升"],"en":["It outperforms older RAG models in both accuracy and speed."]},"click2":{"zh_CN":["对新信息的处理能力强"],"en":["It has strong capabilities for processing new information."]},"click3":{"zh_CN":["在信息变化快的领域特别有优势"],"en":["This is particularly advantageous in fields where information changes rapidly."]}}
---

# LightRAG 的性能表现

<div v-click="1">

- 测试显示，LightRAG 在**准确性**和**速度**上优于旧 RAG 模型

</div>

<div v-click="2">

- 强大的**新信息处理能力**

</div>

<div v-click="3">

- 在信息快速变化的领域尤其有优势

</div>

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)

---
page: 14

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["那 LightRAG 具体怎么工作呢？"],"en":["So, how does LightRAG actually work?"]},"click1":{"zh_CN":["分两个主要阶段：索引和检索"],"en":["It's divided into two main stages: Indexing and Retrieval."]}}
---

# LightRAG 工作流程

分为两个主要阶段：

<div v-click="1">

1. **索引 (Indexing)**：构建知识图谱
2. **检索 (Retrieval)**：双层检索获取信息

</div>

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)

---
page: 15

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["索引阶段就是构建知识图谱："],"en":["The Indexing stage is about building the knowledge graph:"]},"click1":{"zh_CN":["1. 文档切小块"],"en":["1. Chunking the document into small pieces."]},"click2":{"zh_CN":["2. 大模型识别实体（人名、地名等）"],"en":["2. Entity Recognition: The LLM identifies entities (people, places, concepts) in each chunk."]},"click3":{"zh_CN":["3. 模型找出实体间关系，生成实体-关系对"],"en":["3. Relationship Extraction: The model determines the relationships between entities, generating Entity-Relationship pairs."]}}
---

# 索引阶段：创建知识图谱 (1/2)

<div v-click="1">

1. **文档切块 (Chunking)**: 将文档分成小块。

</div>

<div v-click="2">

2. **实体识别 (Entity Recognition)**: LLM 识别每个块中的实体 (人、地、概念)。

</div>

<div v-click="3">

3. **关系提取 (Relationship Extraction)**: 模型确定实体间的关系，生成**实体-关系 key-value 对**。

</div>

---
page: 16

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["4. 用这些对构建图结构，并优化去重"],"en":["4. Knowledge Graph Construction: Combining these pairs into a graph structure, optimized for deduplication."]},"click1":{"zh_CN":["5. 实体关系的描述转成向量","存到向量数据库（默认 Nano Vector）"],"en":["5. Embedding Storage: Entity and relationship descriptions are embedded into vectors,","stored in a vector database (default Nano Vector)."]}}
---

# 索引阶段：创建知识图谱 (2/2)

<div v-click="1">

4. **知识图谱构建 (Knowledge Graph Construction)**: 将实体-关系对组合成**图结构**，并优化去重。

</div>

<div v-click="2">

5. **向量存储 (Embedding Storage)**: 实体和关系的描述被嵌入成向量，存储在**向量数据库** (默认 **Nano Vector**)。

</div>

---
page: 17

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["检索阶段就是双层检索："],"en":["The Retrieval stage is Dual-Level Retrieval:"]},"click1":{"zh_CN":["低层检索：近距离观察，回答精确问题"],"en":["Low-Level Retrieval: Close observation to answer precise questions."]},"click2":{"zh_CN":["高层检索：远距离鸟瞰，提供全局视野"],"en":["High-Level Retrieval: Distant bird's-eye view, providing a global perspective."]},"click3":{"zh_CN":["结合两者以获得全面答案"],"en":["Combining both for comprehensive answers."]}}
---

# 检索阶段：双层检索

- LightRAG 使用**双层检索 (Dual-Level Retrieval)**

<div v-click="1">

- **低层检索**: 近距离观察，回答精确问题

</div>

<div v-click="2">

- **高层检索**: 远距离鸟瞰，提供全局视野

</div>

<div v-click="3">

- 结合两者以获得全面答案

</div>

---
page: 18

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你可以试试看怎么用 LightRAG"],"en":["You can try setting up LightRAG."]},"click1":{"zh_CN":["提供两种设置方法：","1. 使用在线大模型 (如 OpenAI)"],"en":["There are two main setup methods:","1. Using online large models (like OpenAI)"]},"click2":{"zh_CN":["2. 使用免费/本地私有模型 (结合 Ollama)"],"en":["2. Using free/local private models (combined with Ollama)"]}}
---

# 设置 LightRAG: 本地使用

提供两种主要设置方法：

<div v-click="1">

1. 使用在线大模型 (如 OpenAI)

</div>

<div v-click="2">

2. 使用免费/本地私有模型 (结合 Ollama)

</div>

---
page: 19

layout: two-cols
subtitles: {"default":{"zh_CN":["第一种，使用在线大模型（如 OpenAI）","步骤很简单："],"en":["The first method is using online large models (like OpenAI).","The steps are simple:"]},"click1":{"zh_CN":["1. 克隆或安装 LightRAG 代码库"],"en":["1. Clone the repository or install from PyPI."]},"click2":{"zh_CN":["2. 建立虚拟环境"],"en":["2. Create a virtual environment (conda or virtualenv recommended)."]},"click3":{"zh_CN":["3. 安装依赖包"],"en":["3. Install the dependency packages."]}}
---

# 设置 LightRAG (1/4): 使用 OpenAI 模型

**步骤:**

<div v-click="1">

1. 克隆代码库或从 PyPI 安装

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG

# Or Install from PyPI
pip install lightrag-hku
```

</div>

<div v-click="2">

2. 建立虚拟环境 (推荐使用 conda 或 virtualenv)

```bash
conda create -n lightrag python=3.12
conda activate lightrag
```

</div>

<div v-click="3">

3. 安装依赖包

```bash
pip install -e .
```

</div>

::right::



---
page: 20

layout: two-cols
subtitles: {"default":{"zh_CN":["4. 写代码：指定工作目录和模型"],"en":["4. Write code: Specify the working directory and the model."]}}
---

# 设置 LightRAG (2/4): 使用 OpenAI 模型

**步骤:**
4. 索引和查询数据 (示例代码 Part 1)

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

#########
# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()
# import nest_asyncio 


::right::

# nest_asyncio.apply() 
#########

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)
```

---
page: 21

layout: two-cols
subtitles: {"default":{"zh_CN":["代码继续："],"en":["Continuing the code:"]},"click1":{"zh_CN":["传文档内容，调用 rag.insert() 完成索引"],"en":["Provide the document content and call `rag.insert()` to complete indexing."]},"click2":{"zh_CN":["用 rag.query() 提问"],"en":["Use `rag.query()` to ask questions."]}}
---

# 设置 LightRAG (3/4): 使用 OpenAI 模型

**步骤:**
4. 索引和查询数据 (示例代码 Part 2)

```python
with open("./book.txt") as f:
    rag.insert(f.read())

# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))

# Perform local search


::right::

print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))

# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))

# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

<div v-click="1">

- 使用 `rag.insert()` 索引文档内容

</div>

<div v-click="2">

- 使用 `rag.query()` 进行查询

</div>

---
page: 22

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["可以指定不同模式："],"en":["You can specify different modes:"]},"click1":{"zh_CN":["`naive` (标准 RAG)"],"en":["`naive`: Standard RAG."]},"click2":{"zh_CN":["`local` (低层)"],"en":["`local`: Retrieval based on entity neighbors (low-level)."]},"click3":{"zh_CN":["`global` (高层)"],"en":["`global`: Broader global entity relationship retrieval (high-level)."]},"click4":{"zh_CN":["`hybrid` (混合)"],"en":["`hybrid`: Combines local and global modes (hybrid)."]}}
---

# 设置 LightRAG (4/4): 使用 OpenAI 模型

**查询模式 (QueryParam Mode):**

<div v-click="1">

- `naive`: 标准 RAG

</div>

<div v-click="2">

- `local`: 基于实体近邻的检索 (低层)

</div>

<div v-click="3">

- `global`: 更广泛的全局实体关系检索 (高层)

</div>

<div v-click="4">

- `hybrid`: 结合 local 和 global 模式 (混合)

</div>

---
page: 23

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["如果你想用免费或本地私有模型？","LightRAG 也支持！","结合 Ollama 工具使用很方便"],"en":["What if you want to use free or local private models?","LightRAG supports that too!","It's convenient to use with the Ollama tool."]},"click1":{"zh_CN":["初始化时指定 Ollama 相关参数","代码结构与使用 OpenAI 模型类似"],"en":["Specify Ollama-related parameters when initializing `LightRAG`.","The code structure is similar to using OpenAI models."]}}
---

# 设置 LightRAG: 使用免费/私有模型

- 可以结合 **Ollama** 工具使用免费或本地私有模型

<div v-click="1">

- 初始化 `LightRAG` 时指定 Ollama 相关参数
- 代码结构与使用 OpenAI 模型类似

</div>

---
page: 24

layout: two-cols
subtitles: {"default":{"zh_CN":["初始化时，指定 Ollama 模型函数","和你的模型名字（如 llama2）"],"en":["When initializing, specify the Ollama model function,","and the name of your model (e.g., llama2)."]},"click1":{"zh_CN":["还需要指定嵌入函数 embedding_func","告诉 LightRAG 用哪个 Ollama 模型生成向量","比如例子里的 nomic-embed-text"],"en":["You also need to specify the embedding function `embedding_func`","to tell LightRAG which Ollama model to use for generating vectors,","like `nomic-embed-text` in the example."]}}
---

# 设置 LightRAG (Ollama 示例 1/2)

```python
import os

from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete, # 指定 Ollama 模型函数
    llm_model_name="your_model_name", # 指定你的模型名字 (如 llama2)


::right::

    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"), # 指定嵌入模型
    ),
)
```
- 指定 Ollama 模型函数
- 指定你的模型名字 (如 llama2)

<div v-click="1">

- 指定嵌入函数 embedding_func
- 告诉 LightRAG 用哪个 Ollama 模型生成向量
- 比如例子里的 nomic-embed-text

</div>

---
page: 25

layout: two-cols
subtitles: {"default":{"zh_CN":["代码继续："],"en":["Continuing the code:"]},"click1":{"zh_CN":["剩下的步骤一样：插入文档，不同模式查询"],"en":["The remaining steps are the same: insert the document and query in different modes."]}}
---

# 设置 LightRAG (Ollama 示例 2/2)

```python
with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)

# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))


::right::

)

# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)

# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```

<div v-click="1">

- 插入文档和查询步骤与 OpenAI 方法相同

</div>

---
page: 26

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 特别适合处理复杂文档","或需深入分析概念关系行业"],"en":["LightRAG is particularly suitable for handling complex documents,","or industries requiring in-depth analysis of entity relationships."]},"click1":{"zh_CN":["比如：法律研究","理清法律条文、案例间联系"],"en":["For example: Legal research,","clarifying the relationships between laws, cases, and precedents."]},"click2":{"zh_CN":["医疗健康","分析病人数据、症状、治疗方案，发现洞察"],"en":["Healthcare,","analyzing patient data, symptoms, and treatment plans to discover insights."]},"click3":{"zh_CN":["农业","组织和检索作物、土壤、天气信息，支持决策"],"en":["Agriculture,","organizing and retrieving information about crops, soil, and weather to support decision-making."]}}
---

# LightRAG 的关键用例

特别适合处理**复杂文档**或需要**实体关系分析**的行业：

<div v-click="1">

- **法律研究**: 提取法律、案例、先例间关系。

</div>

<div v-click="2">

- **医疗健康**: 分析病人数据、症状、治疗方案，发现洞察。

</div>

<div v-click="3">

- **农业**: 组织和检索作物、土壤、天气信息，支持决策。

</div>

---
page: 27

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["总的来说，LightRAG 代表 RAG 技术重要进展"],"en":["In summary, LightRAG represents a significant advancement in RAG technology."]},"click1":{"zh_CN":["结合知识图谱和向量检索","做到轻量化和成本效益"],"en":["It integrates knowledge graphs and vector retrieval,","achieving lightweight design and cost-effectiveness."]},"click2":{"zh_CN":["增量更新能力和双层检索功能","实用性超越现有方法，比如 GraphRAG"],"en":["Its incremental update capability and dual-level retrieval features","surpass existing methods, such as GraphRAG, in practicality."]},"click3":{"zh_CN":["如果你有大量数据处理需求","或想构建智能、有上下文应答系统","LightRAG 是非常值得尝试的开源方案"],"en":["If you have large data processing needs,","or want to build an intelligent, context-aware response system,","LightRAG is a highly recommended open-source solution."]}}
---

# 总结：为何选择 LightRAG

- 代表 **RAG 技术的新进展**

<div v-click="1">

- 集成**知识图谱** + **向量检索**
- **轻量化**、**成本效益高**

</div>

<div v-click="2">

- **增量更新**、**双层检索**等优势超越现有方法 (如 GraphRAG)

</div>

<div v-click="3">

- 适用于**大型数据集**和需要**智能、上下文感知**回答的场景

</div>

---
page: 28

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["希望我的介绍对你有启发！","好了，聊了这么多 LightRAG"],"en":["I hope my introduction has been inspiring!","Alright, we've talked a lot about LightRAG."]},"click1":{"zh_CN":["我想最后留一个问题让你思考："],"en":["I'd like to leave you with a question to think about:"]},"click2":{"zh_CN":["在你自己的学习、工作、生活里","有没有哪个场景特别需要这种信息处理方式？"],"en":["In your own studies, work, or life,","is there any scenario that particularly needs this kind of information processing method?"]},"click3":{"zh_CN":["你会怎么用 LightRAG 来解决这个问题呢？"],"en":["How would you use LightRAG to solve this problem?"]}}
---

# 结束语

- LightRAG 是一个强大、开源的下一代 RAG 解决方案。
- 鼓励大家尝试体验。

<div v-click="1">

**思考问题:**

</div>

<div v-click="2">

在你自己的学习、工作、生活里，有没有哪个场景特别需要这种信息处理方式？

</div>

<div v-click="3">

你会怎么用 LightRAG 来解决这个问题呢？

</div>