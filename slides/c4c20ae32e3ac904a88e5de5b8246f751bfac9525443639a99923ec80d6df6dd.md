---
page: 1

theme: seriph
background: https://cover.sli.dev
title: LightRAG: 下一代检索增强生成（RAG）框架
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.1|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["好的，没问题！","咱们今天来聊聊一个挺有意思的新东西，","它是关于怎么让大型语言模型（LLMs）变得更聪明、","更懂你的文档内容的。","你知道吗，","咱们平时用的很多AI工具，","包括聊天机器人什么的，","它们之所以能回答问题，","很大一部分是因为它们能从外部数据里找到信息。","这个技术呢，","有个名字叫 RAG，","就是“检索增强生成”。","想象一下，","你的AI就像一个超级聪明的学生，","但它脑子里的知识是有限的。","RAG就像是给这个学生配了一个无敌的图书馆，","而且还有个特别厉害的图书管理员。","当它遇到一个问题，它不会瞎编，","而是先跑到图书馆里，","让图书管理员帮忙找到最相关的书页，","然后再根据这些书页来组织答案。","这样是不是听起来就靠谱多了？"],"en":["Okay, no problem!","Today, we're going to talk about something quite interesting,","It's about how to make Large Language Models (LLMs) smarter,","and better understand the content of your documents.","Did you know,","Many of the AI tools we use daily,","Including chatbots and so on,","The reason they can answer questions,","Is largely because they can find information from external data.","This technique,","Is called RAG,","Which stands for \"Retrieval-Augmented Generation.\"","Imagine,","Your AI is like a super smart student,","But its knowledge is limited.","RAG is like giving this student an invincible library,","And also a very capable librarian.","When it encounters a question, it doesn't just make things up,","Instead, it first goes to the library,","Asks the librarian to help find the most relevant pages,","And then organizes the answer based on those pages.","Doesn't that sound much more reliable?"]}}
---

# LightRAG: A GraphRAG Alternative

## What is RAG?

- **R**etrieval-**A**ugmented **G**eneration
- Combines LLM strengths with external data
- AI finds relevant info before generating response
- Like a smart student with a powerful library and librarian

---
page: 2

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["好，回到咱们今天的主题。","我看到这篇文章里介绍了一个叫 LightRAG 的新框架。","它说自己是一个进阶版的、","更划算高效的 RAG 框架。","它跟传统的 RAG 有啥不一样呢？","它利用了知识图谱和向量检索技术。"],"en":["Okay, back to our topic today.","I saw this article introducing a new framework called LightRAG.","It claims to be an advanced,","More cost-effective and efficient RAG framework.","How is it different from traditional RAG?","It leverages Knowledge Graphs and Vector Retrieval technologies."]},"click1":{"zh_CN":["传统的 RAG 方法通常会把你的文档切成一块一块的小片段，","然后去搜索这些片段。","但这有个问题，","就是片段之间的联系、上下文关系很容易就丢了。","比如一件事的起因和结果可能在不同的段落里，","传统的RAG就可能只找到其中一部分，","答案就不完整。","LightRAG 在这里就玩了个花活儿！","它不仅切块，","还会去建立一个叫“知识图谱”的东西。","你可以把它想象成一张巨大的思维导图，","把文档里提到的人物、地点、概念等等都变成节点，","然后用线把它们之间的关系连接起来。","比如，“A写了书B”，","“B影响了C”。","对，它构建的是一种“实体-关系对”，","这样即使信息分布在不同地方，","通过知识图谱也能把相关的概念串起来，","保留住上下文关系。"],"en":["Traditional RAG methods usually split your document into small chunks,","And then search these fragments.","But there's a problem with this,","The connections and contextual relationships between fragments are easily lost.","For example, the cause and effect of an event might be in different paragraphs,","Traditional RAG might only find part of it,","And the answer won't be complete.","LightRAG does something clever here!","It doesn't just chunk,","It also builds something called a \"Knowledge Graph.\"","You can imagine it as a huge mind map,","Turning people, places, concepts, etc., mentioned in the document into nodes,","And then connecting their relationships with lines.","For example, \"A wrote book B\",","\"B influenced C\".","Yes, it builds \"Entity-Relationship Pairs\",","So even if information is scattered in different places,","The knowledge graph can connect related concepts,","Preserving contextual relationships."]},"click2":{"zh_CN":["跟传统的 RAG 相比,","它解决了文档片段之间上下文丢失的问题。"],"en":["Compared to traditional RAG,","It addresses the issue of losing context between document segments."]}}
---

# What is LightRAG?

## An Advanced, Cost-Effective RAG Framework

- Leverages **Knowledge Graphs** and **Vector Retrieval**

<div v-click="1">

- Goes beyond simple chunking
- Builds **Entity-Relationship Pairs**
  - Preserves contextual relationships

</div>

<div v-click="2">

- Compared to traditional RAG:
  - Addresses loss of context between document segments

</div>

---
page: 3

layout: two-cols
subtitles: {"default":{"zh_CN":["嘿，你可能听说过微软也有一个类似的东西叫 GraphRAG。","LightRAG 呢，可以看作是 GraphRAG 的一个替代品，","而且它说自己有挺多优势的。","没错。","根据我看到的信息，","跟 GraphRAG 相比，LightRAG 重点在于更快、更省钱，","而且支持增量更新。"],"en":["Hey, you might have heard that Microsoft also has something similar called GraphRAG.","LightRAG, well, can be seen as an alternative to GraphRAG,","And it claims to have quite a few advantages.","That's right.","According to the information I've seen,","Compared to GraphRAG, LightRAG focuses on being faster, more affordable,","And supports incremental updates."]},"click1":{"zh_CN":["GraphRAG 听起来很厉害，","但它可能需要调用大量的 API，","还得用比较贵的模型，","每次数据更新都要重建整个图谱，","这成本就上去了。"],"en":["GraphRAG sounds impressive,","But it might require calling a large number of APIs,","And also use relatively expensive models,","Each time data is updated, the entire graph needs to be rebuilt,","Which drives up the cost."]},"click2":{"zh_CN":["LightRAG 就不一样了，","它可以用更少的 API 调用，","支持更轻量的模型（比如 GPT-4-mini），"],"en":["LightRAG is different,","It can use fewer API calls,","Supports lighter models (like GPT-4-mini),"]},"click3":{"zh_CN":["最关键的是，它能增量更新图谱。","增量更新是啥意思呢？","就是说，如果你的资料库里新增了一些信息，","或者修改了一点东西，","LightRAG 不用推倒重来，","它就像往那张巨大的思维导图里加几个新节点、","连几根新线就行了。","这在信息更新特别快的领域，","比如科技、新闻或者法律法规这种，简直是救命稻草！","你的AI随时都能掌握最新的情况，","不会给你一个过时的答案。","而且，它支持双层检索。"],"en":["The most crucial point is that it can perform Incremental Updates to the graph.","What does incremental update mean?","It means that if you add some new information to your database,","Or modify something slightly,","LightRAG doesn't need to start over,","It's like adding a few new nodes to that giant mind map,","Just connect a few new lines.","This is a lifesaver in fields where information updates very quickly,","Like technology, news, or legal regulations!","Your AI can keep up with the latest information at any time,","Without giving you outdated answers.","Furthermore, it supports Dual-Level Retrieval."]}}
---

# LightRAG vs GraphRAG

## A Faster, More Affordable Alternative

<div v-click="1">

- **GraphRAG Limitations:**
  - Resource-intensive (hundreds of API calls)
  - Requires expensive models (e.g., GPT-4o)
  - Rebuilds entire graph on update (costly)

</div>

<div v-click="2">

- **LightRAG Advantages:**
  - Uses fewer API calls & lighter models (e.g., GPT-4-mini)

</div>

<div v-click="3">

  - **Incremental Updates**
  - Supports Dual-Level Retrieval

</div>


::right::


![Evaluation Screenshot](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)

---
page: 4

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["除了知识图谱，LightRAG 还结合了向量检索（Vector-based retrieval）。","这两种方式一起用，就是它的“双层检索”系统。","LightRAG 的工作流程主要分为两个阶段：索引和检索。","首先是索引阶段，也就是创建知识图谱。","大家看一下这个流程图。"],"en":["Besides knowledge graphs, LightRAG also combines vector-based retrieval.","Using these two methods together is its \"dual-level retrieval\" system.","LightRAG's workflow is mainly divided into two stages: indexing and retrieval.","First is the indexing stage, which is creating the knowledge graph.","Let's take a look at this flowchart."]},"click1":{"zh_CN":["第一个步骤是文档分块（Chunking）。"],"en":["The first step is document chunking."]},"click2":{"zh_CN":["然后通过LLM进行实体识别（Entity Recognition）。"],"en":["Then perform Entity Recognition using an LLM."]},"click3":{"zh_CN":["接着提取实体间的关系，生成实体-关系对。"],"en":["Next, extract relationships between entities to generate entity-relationship pairs."]},"click4":{"zh_CN":["这些对再被用来构建和优化知识图谱。"],"en":["These pairs are then used to construct and optimize the knowledge graph."]},"click5":{"zh_CN":["最后，将描述和关系转化为向量，存储到向量数据库中，比如 LightRAG 默认使用的 Nano Vector。"],"en":["Finally, convert the descriptions and relationships into vectors and store them in a Vector Database, such as Nano Vector, which LightRAG uses by default."]}}
---

# LightRAG Workflow

## 1. Indexing Process: Creating Knowledge Graphs

<div v-click="1">

1.  **Chunking:** Divide documents

</div>

<div v-click="2">

2.  **Entity Recognition:** Identify entities (LLM)

</div>

<div v-click="3">

3.  **Relationship Extraction:** Generate entity-relationship pairs (LLM)

</div>

<div v-click="4">

4.  **Knowledge Graph Construction:** Combine pairs, optimize

</div>

<div v-click="5">

5.  **Embedding Storage:** Store embeddings in Vector Database (e.g., Nano Vector)

</div>

![LightRAG Workflow Diagram](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)

---
page: 5

layout: two-cols
subtitles: {"default":{"zh_CN":["接下来是检索阶段，也就是它的双层检索。","它有两种检索模式：","结合了本地和全局查询。"],"en":["Next is the retrieval stage, which is its dual-level retrieval.","It has two retrieval modes:","Combines Local and Global queries."]},"click1":{"zh_CN":["低层检索 (Low Level Retrieval):","这种模式侧重于查询与某个特定实体（节点）紧密相连的“邻居”，","也就是它周围的局部信息。","这特别适合用来回答精确的、事实性的问题，","比如问某个具体的数据、法规条文等等。"],"en":["Low Level Retrieval:","This mode focuses on querying the \"neighbors\" closely connected to a specific entity (node),","Which is its surrounding local information.","This is particularly suitable for answering precise, factual queries,","Such as asking for specific statistics, regulation clauses, and so on."]},"click2":{"zh_CN":["高层检索 (High-Level Retrieval):","这种模式则会在整个图谱里寻找更宏观、更全局的联系和主题。","它能帮你把握整体的趋势和背景信息，","比如讨论某个领域的整体发展方向","或者不同概念之间的内在逻辑。"],"en":["High-Level Retrieval:","This mode searches the entire graph for more macroscopic, global connections and themes.","It helps you grasp overall trends and background information,","For example, discussing the overall development direction of a field,","Or the intrinsic logic between different concepts."]},"click3":{"zh_CN":["哈哈，这就像是你有两种查资料的方法：","一种是精确查找某个词在书的哪一页，","另一种是快速浏览章节标题和摘要，","把握整本书的脉络。","LightRAG 把这两种方法结合起来，","所以它给出的答案就能既有详细的事实支撑，","又有全面的上下文理解。","它提供的是既有事实又有上下文的答案。"],"en":["Haha, it's like having two ways to look up information:","One is to precisely find which page a certain word is on in a book,","The other is to quickly skim through chapter titles and summaries,","To grasp the outline of the whole book.","LightRAG combines these two methods,","So the answers it provides can have both detailed factual support,","And comprehensive contextual understanding.","It provides answers with both facts and context."]}}
---

# LightRAG Workflow

## 2. Dual-Level Retrieval

- Combines **Local** and **Global** queries

<div v-click="1">

- **Low Level Retrieval:**
  - Focuses on nearby nodes (local context)
  - Answers **precise, factual** queries
  - *Example: Specific stats, regulations*

</div>

<div v-click="2">

- **High-Level Retrieval:**
  - Identifies overarching themes (global context)
  - Answers **broader, conceptual** queries
  - *Example: Environmental trends, future directions*

</div>

<div v-click="3">

> Provides both **facts** and **context**

</div>

::right::



---
page: 6

layout: two-cols
subtitles: {"default":{"zh_CN":["文章里也提到，测试结果显示，","跟老方法比，LightRAG 在准确性和速度上都有显著提升，","而且它能很优雅地处理新信息。","至于怎么用起来，文章里也说了，","其实不难。","你可以在本地搭建。","它提供了使用 OpenAI 模型（比如 GPT-4o-mini）的例子，","首先是安装和设置。"],"en":["The article also mentioned that test results show,","Compared to older methods, LightRAG significantly improves accuracy and speed,","And it can handle new information elegantly.","As for how to get started, the article also explained,","It's actually not difficult.","You can set it up locally.","It provides examples of using OpenAI models (like GPT-4o-mini),","First is installation and setup."]},"click1":{"zh_CN":["第一步是克隆仓库或者通过 pip 安装。"],"en":["Step one is to clone the repository or install via pip."]},"click2":{"zh_CN":["第二步，推荐设置虚拟环境。"],"en":["Step two, it's recommended to set up a virtual environment."]},"click3":{"zh_CN":["第三步，安装依赖。"],"en":["Step three, install dependencies."]},"click4":{"zh_CN":["第四步，索引和运行查询，代码在下一页幻灯片展示。"],"en":["Step four, indexing and running queries, the code is shown on the next slide."]}}
---

# Setting Up LightRAG (OpenAI Models)

## Step-by-Step Guide

<div v-click="1">

1.  **Clone Repository:**
    ```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
# Or Install from PyPI
pip install lightrag-hku
    ```

</div>

<div v-click="2">

2.  **Set Up Virtual Environment:**
    ```bash
conda create -n lightrag python=3.12
conda activate lightrag
    ```

</div>

<div v-click="3">

3.  **Install Dependencies:**
    ```bash
pip install -e .
    ```

</div>

<div v-click="4">

4.  **Index & Run Queries:** (See next slide for code)

</div>

::right::



---
page: 7

layout: two-cols
subtitles: {"default":{"zh_CN":["关于这段代码，它展示了如何使用 OpenAI 模型来设置和运行 LightRAG。","首先导入必要的库，设置工作目录。","然后实例化 LightRAG 对象，指定工作目录和要使用的 LLM 模型，这里用的是 `gpt_4o_mini_complete`，你也可以选择 `gpt_4o_complete`。","接着打开你的文档文件（比如这里的 \"book.txt\"），并使用 `rag.insert()` 方法将文档内容索引到 LightRAG 中。","最后，通过 `rag.query()` 方法进行查询，可以指定不同的检索模式：naive、local、global、或者 hybrid。","这些模式对应了标准 RAG、基于实体邻域的检索、更广泛的全局关系检索以及两者的结合。"],"en":["Regarding this code, it demonstrates how to set up and run LightRAG using OpenAI models.","First, import the necessary libraries and set the working directory.","Then, instantiate the LightRAG object, specifying the working directory and the LLM model to use. Here, `gpt_4o_mini_complete` is used, you can also choose `gpt_4o_complete`.","Next, open your document file (like \"book.txt\" here), and use the `rag.insert()` method to index the document content into LightRAG.","Finally, perform queries using the `rag.query()` method, specifying different retrieval modes: naive, local, global, or hybrid.","These modes correspond to standard RAG, retrieval based on entity neighborhoods, broader global relationship retrieval, and a combination of both."]}}
---

# Setting Up LightRAG (OpenAI Models)

## Step 4: Index & Run Queries

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,


::right::

    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)

with open("./book.txt") as f:
    rag.insert(f.read())

# Perform different search modes
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

- **Query Modes:** naive, local, global, hybrid

---
page: 8

layout: two-cols
subtitles: {"default":{"zh_CN":["同时也给出了使用免费和本地私有模型（比如 Ollama）的配置方法。","请看这段代码。","这里使用了 Ollama 模型。","跟之前类似，导入必要的库。","关键在于实例化 LightRAG 时，将 `llm_model_func` 设置为 `ollama_model_complete`，并指定 `llm_model_name`。","同时，需要为 embedding 指定一个函数 `embedding_func`，这里使用了 `ollama_embedding`。","代码的其余部分，包括读取文件和进行不同模式的查询，与使用 OpenAI 模型基本相同。","这意味着你不一定非得花大钱用那些商业模型，","也能体验这个框架的强大之处。"],"en":["It also provides configuration methods for using free and local private models (like Ollama).","Please look at this code.","Ollama models are used here.","Similar to before, import the necessary libraries.","The key is during LightRAG instantiation, set `llm_model_func` to `ollama_model_complete`, and specify `llm_model_name`.","Meanwhile, you need to specify a function `embedding_func` for embedding, here `ollama_embedding` is used.","The rest of the code, including reading the file and performing queries in different modes, is essentially the same as when using OpenAI models.","This means you don't necessarily have to spend a lot of money on commercial models,","You can still experience the power of this framework."]}}
---

# Setting Up LightRAG (Free/Private Models)

## Using Ollama Models

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",


::right::

    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)

with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform queries using different modes
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

> Use `ollama_model_complete` and `ollama_embedding`

---
page: 9

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["这样的特性让 LightRAG 在一些特定领域特别有用，","文章里举了几个例子：","特别适合处理复杂文档和进行实体分析的场景。"],"en":["Such features make LightRAG particularly useful in some specific fields,","The article gives a few examples:","Ideal for scenarios involving complex documents and entity analysis."]},"click1":{"zh_CN":["法律研究：","帮你理清法律条文、案例、判例之间的复杂关系。"],"en":["Legal Research:","Helps you clarify the complex relationships between laws, cases, and precedents."]},"click2":{"zh_CN":["医疗保健：","分析病人的数据、症状、治疗方案，","找出潜在的医疗洞察。"],"en":["Healthcare:","Analyzing patient data, symptoms, and treatments,","Identifying potential medical insights."]},"click3":{"zh_CN":["农业：","帮你组织和检索关于农作物、土壤类型、天气模式等信息。"],"en":["Agriculture:","Helps you organize and retrieve information about crops, soil types, weather patterns, etc."]}}
---

# Key Use Cases for LightRAG

## Ideal for Complex Documents & Entity Analysis

<div v-click="1">

- **Legal Research:** Analyzing laws, cases, and precedents.

</div>

<div v-click="2">

- **Healthcare:** Analyzing patient data, symptoms, and treatments.

</div>

<div v-click="3">

- **Agriculture:** Organizing data on crops, soil, and weather.

</div>

---
page: 10

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["感觉怎么样？是不是觉得挺厉害的？","总结一下，LightRAG 把知识图谱和向量检索结合起来，","又快又省钱，","还能轻松应对信息更新，","给你既有细节又有全局观的答案。","可以说，它确实代表了 RAG 技术的一个“下一代”方向，","特别是如果你需要处理大量复杂的数据，","或者想要一个既智能又理解上下文的回答。"],"en":["How does it feel? Do you think it's quite impressive?","To summarize, LightRAG combines knowledge graphs and vector retrieval,","It's fast and cost-effective,","And can easily handle information updates,","Giving you answers with both details and a global perspective.","It can be said that it truly represents a \"next-generation\" direction for RAG technology,","Especially if you need to process large amounts of complex data,","Or want answers that are both intelligent and context-aware."]},"click1":{"zh_CN":["它是一个强大、开源的解决方案，适用于大型数据集和上下文感知的响应。","所以，说到这里，我想问问你，","在你自己的工作或者学习中，","有没有遇到过需要处理大量信息，","而且信息之间关系复杂、还经常更新的情况？","如果让你用上 LightRAG 这种能构建知识图谱的工具，","你觉得它能在哪些方面帮到你呢？","嗯，今天就聊到这儿！","希望这个介绍对你有启发。"],"en":["It is a powerful, open-source solution for large datasets and context-aware responses.","So, speaking of this, I want to ask you,","In your own work or studies,","Have you encountered situations where you need to process a lot of information,","And the relationships between pieces of information are complex and frequently updated?","If you were to use a tool like LightRAG that can build knowledge graphs,","In what areas do you think it could help you?","Okay, that's all for today!","I hope this introduction was insightful for you."]}}
---

# Conclusion: Why Choose LightRAG?

## Next-Generation RAG Solution

- Combines Knowledge Graph & Vector Retrieval
- Fast & Cost-Effective
- Supports Incremental Updates
- Dual-Level Retrieval (Facts + Context)
- Works with local/smaller models

<div v-click="1">

> Powerful, open-source for large datasets & context-aware responses.

</div>