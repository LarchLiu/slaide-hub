---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG: 一种经济高效的 GraphRAG 替代方案"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.2|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["嘿，你好！今天想跟你聊一个特别有意思、而且挺实用的技术，","它能让电脑理解文件的方式变得超级不一样，","而且可能更聪明、更省钱！","我们平时用的一些智能助手啊，或者搜索工具啊，","虽然能找到信息，但有时候总觉得差点意思，对吧？","它们可能就给你一堆零散的片段，让你自己去拼凑。","今天介绍的这个，或许就能给你一个“啊哈！”的时刻。"],"en":["Hey there! Today, I want to talk to you about a really interesting and practical technology.","It can make the way computers understand documents completely different,","and potentially smarter and more cost-effective!","You know, the smart assistants or search tools we use sometimes,","While they can find information, they sometimes feel a bit lacking, right?","They might just give you a bunch of scattered snippets, leaving you to piece them together yourself.","What I'm introducing today might just give you that 'aha!' moment."]}}
---

# LightRAG: 下一代RAG框架

- 提升文档交互的效率与智能
- 解决传统RAG的局限性

---
page: 2

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["我们今天要讲的是一个叫做 LightRAG 的东西。","你知道吗，现在用大型语言模型（LLM）和外部数据结合，","生成更准确、更及时回答的技术叫 RAG（Retrieval-Augmented Generation）。","传统的做法是把文档切成一块块，然后去搜相关的片段，","再把这些片段喂给 LLM 生成答案。","但这你想啊，一篇文章里的意思经常是连着的，切开了可能就丢了上下文。","对不对？","如果一个概念或者一个事实分散在好几个不同的块里，","或者关键的逻辑关系跨了好几个段落，","传统的 RAG 就很难给你一个连贯、准确的回答，尤其是在面对一些复杂的问题时。"],"en":["What we're discussing today is something called LightRAG.","Did you know that combining Large Language Models (LLM) with external data","to generate more accurate and timely answers is called RAG (Retrieval-Augmented Generation)?","The traditional approach involves splitting documents into chunks, then retrieving relevant pieces,","and feeding these pieces to the LLM to generate an answer.","But think about it, the meaning in an article is often interconnected; splitting it might lose the context.","Right?","If a concept or fact is spread across several different chunks,","or if key logical relationships span multiple paragraphs,","traditional RAG struggles to provide a coherent and accurate answer, especially for complex questions."]}}
---

# 什么是 Retrieval-Augmented Generation (RAG)?

- **核心思想**: 结合大型语言模型 (LLM) 和外部数据
- **传统RAG**: 文档分块 (Chunks) -> 检索相关块 -> 喂给LLM生成答案
- **传统RAG的局限**: 难以捕捉跨块的**上下文关系**
  - 关键信息分散在多个块中
  - 复杂问题回答不准确

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)
*传统RAG可能遇到的问题示意*

---
page: 3

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["我今天要说的 LightRAG 呢，它的厉害之处就在于，","它不光是切块找词，它会去理解文件里的“关系”。","就像你大脑里想东西不是一个个孤立的点，","而是把人、事、地点、概念什么的都连起来形成一个网络一样。","LightRAG 也一样，它会构建一个“知识图谱”，","把信息里的实体（比如人名、地名、概念）和它们之间的关系给抓出来，","变成一对对“实体-关系”的数据。","这种方式就能保留信息之间的上下文连接。"],"en":["Now, the cool thing about LightRAG, which I'm introducing today, is that","It doesn't just split chunks and find words; it understands the 'relationships' within the document.","It's like how your brain doesn't think in isolated points,","but connects people, events, places, concepts, and so on, forming a network.","LightRAG does the same; it builds a 'Knowledge Graph',","extracting the entities (like names, places, concepts) and their relationships from the information,","turning them into 'entity-relationship pairs'.","This method helps preserve the contextual connections between pieces of information."]}}
---

# Introducing LightRAG

- **定义**: 先进、经济高效的 RAG 框架
- **核心创新**: 集成**知识图谱**与**向量检索**
- **超越传统RAG**: 构建**实体-关系对**，保留文档间的上下文联系
- **工作方式**: 像大脑一样，将概念（实体）互相关联形成网络（图谱）

---
page: 4

layout: two-cols
subtitles: {"default":{"zh_CN":["那可能有人听过微软的 GraphRAG，它也是用图谱的。","这确实是个好想法，但 LightRAG 呢，","我发现它有几个特别大的优势，让它更适合咱们用，","尤其是当你对成本和效率比较在意的时候。","第一是“快”，第二是“省钱”。","怎么说呢？"],"en":["Some of you might have heard of Microsoft's GraphRAG, which also uses the graph idea.","That's definitely a good concept, but LightRAG,","I found it has a few particularly big advantages that make it more suitable for us,","especially if you're concerned about cost and efficiency.","The first is 'speed', and the second is 'cost-effectiveness'.","How so?"]},"click1":{"zh_CN":["GraphRAG 可能需要调用很多次昂贵的模型（比如 GPT-4o）来构建和处理图谱，","而且每次数据有更新，它得把整个图谱重新建一遍，这花钱又花时间，资源消耗挺大的。"],"en":["GraphRAG might require many calls to expensive models (like GPT-4o) to build and process the graph,","and every time data is updated, it has to completely rebuild the entire graph, which is costly and time-consuming, consuming significant resources."]},"click2":{"zh_CN":["LightRAG 就聪明多了，它用的 API 调用少，","可以用更轻量级的模型（比如 GPT-4o-mini）来做这些事，成本自然就下来了。","而且更牛的是，它可以“增量更新”！","新的信息来了，它不用推倒重来，直接加进去就行，"],"en":["LightRAG is much smarter; it uses fewer API calls,","and can use lighter models (like GPT-4o-mini) for these tasks, naturally lowering the cost.","What's even better is that it supports 'incremental updates'!","When new information arrives, it doesn't have to start over; it can just add it in directly,"]}}
---

# LightRAG vs. GraphRAG

- **GraphRAG (Microsoft)**: 也是基于图谱的思想

<div v-click="1">

- **GraphRAG 局限性**:
    - 资源密集，需要大量昂贵的 API 调用 (如 GPT-4o)
    - 每次数据更新需**完全重建**图谱，成本高昂

</div>

<div v-click="2">

- **LightRAG 优势**:
    - 更快，更经济
    - 使用更少的 API 调用，支持轻量级模型 (如 GPT-4o-mini)
    - 支持图谱的**增量更新**，无需完全重建
    - 支持**双层检索** (Local & Global) 提升响应质量

</div>

::right::



---
page: 5

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["这在信息变动很快的领域简直是救星，","比如新闻啊、技术文档啊什么的，你的知识库能时刻保持最新。"],"en":["This is a lifesaver in fields where information changes quickly,","like news or technical documents, your knowledge base can stay constantly updated."]},"click1":{"zh_CN":["它不光是切块找词，它会去理解文件里的“关系”。","就像你大脑里想东西不是一个个孤立的点，","而是把人、事、地点、概念什么的都连起来形成一个网络一样。","LightRAG 也一样，它会构建一个“知识图谱”，","把信息里的实体（比如人名、地名、概念）和它们之间的关系给抓出来，","变成一对对“实体-关系”的数据。","这种方式就能保留信息之间的上下文连接。","Faster, Smarter Retrieval with Graphs","By combining graphs with vector-based search (a fancy way of saying it finds related items quickly), LightRAG ensures that responses are not just accurate but also fast."],"en":["It doesn't just split chunks and find words; it understands the 'relationships' within the document.","It's like how your brain doesn't think in isolated points,","but connects people, events, places, concepts, and so on, forming a network.","LightRAG does the same; it builds a 'Knowledge Graph',","extracting the entities (like names, places, concepts) and their relationships from the information,","turning them into 'entity-relationship pairs'.","This method helps preserve the contextual connections between pieces of information.","Faster, Smarter Retrieval with Graphs","By combining graphs with vector-based search (a fancy way of saying it finds related items quickly), LightRAG ensures that responses are not just accurate but also fast."]},"click2":{"zh_CN":["The system organizes related ideas efficiently, and its deduplication feature removes repetitive information — making sure the user only gets what matters most."],"en":["The system organizes related ideas efficiently, and its deduplication feature removes repetitive information — making sure the user only gets what matters most."]},"click3":{"zh_CN":["Why LightRAG Matters","Tests show that LightRAG significantly improves both accuracy and speed compared to older RAG models."],"en":["Why LightRAG Matters","Tests show that LightRAG significantly improves both accuracy and speed compared to older RAG models."]},"click4":{"zh_CN":["It also handles new information gracefully, meaning you get up-to-date and context-aware answers every time."],"en":["It also handles new information gracefully, meaning you get up-to-date and context-aware answers every time."]}}
---

# LightRAG 关键优势总结

- **适应快速变化**: 增量更新系统，保持信息时效性

<div v-click="1">

- **更快更智能**: 结合图谱和向量搜索，高效组织信息

</div>

<div v-click="2">

- **去重**: 移除重复信息，只保留关键内容

</div>

<div v-click="3">

- **效果提升**: 测试显示，显著提高**准确性**和**速度**

</div>

<div v-click="4">

- **应用广泛**: 适用于聊天机器人、智能助手、动态搜索等场景

</div>

*This makes it a game-changer for applications where quick, relevant responses are key — like chatbots, personal assistants, and dynamic search tools.*

---
page: 6

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["从技术上看，LightRAG 的工作流程主要分两大步：","“索引”（Index）和“检索”（Retrieval）。","大家看一下幻灯片上的流程图。"],"en":["From a technical perspective, LightRAG's workflow is mainly divided into two major steps:","'Indexing' and 'Retrieval'.","Please take a look at the flowchart on the slide."]}}
---

# LightRAG 工作流程

LightRAG 的工作流程主要分为两大阶段:

1.  **索引 (Indexing)**: 构建知识图谱和存储向量
2.  **检索 (Retrieval)**: 利用图谱和向量数据库查找答案

大家看一下幻灯片上的流程图。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)
*LightRAG Workflow*

---
page: 7

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["“索引”阶段就像是给你的文件建一个超级智能、带关系网的目录。","首先，它会把你的文档分成一个个小块。"],"en":["The 'Indexing' phase is like building a super-smart directory with a relationship network for your files.","First, it divides your document into smaller chunks."]},"click1":{"zh_CN":["接着，让一个语言模型去识别出每个小块里的关键“实体”，","也就是里面提到的重要的人、地方、概念等等。"],"en":["Next, it uses a language model to identify the key 'entities' within each chunk,","which are the important people, places, concepts, etc., mentioned."]},"click2":{"zh_CN":["然后，模型会进一步分析，找出这些实体之间有什么“关系”，","比如“人物A写了书B”，“地点C发生了事件D”。","这些找出来的关系，一条一条地，最终就用来构建那个“知识图谱”。"],"en":["Then, the model further analyzes and finds out what 'relationships' exist between these entities,","for example, 'Person A wrote Book B', 'Event D occurred in Place C'.","These identified relationships, one by one, are eventually used to build that 'Knowledge Graph'."]},"click3":{"zh_CN":["在这个图谱构建过程中，它还会把重复的实体或关系去掉，","让图谱更精炼、更高效。"],"en":["During this graph construction process, it also removes duplicate entities or relationships,","making the graph more streamlined and efficient."]},"click4":{"zh_CN":["最后，它会把这些实体和关系的描述转换成数字形式，也就是所谓的“向量”，","存到一个专门的“向量数据库”里，方便后续快速检索。","我了解到，LightRAG 默认用的是一个叫 Nano Vector 的数据库。"],"en":["Finally, it converts the descriptions of these entities and relationships into a numerical format, known as 'vectors',","and stores them in a dedicated 'vector database' for subsequent rapid retrieval.","I learned that LightRAG uses a database called Nano Vector by default."]}}
---

# 1. 索引过程: 构建知识图谱

- **Chunking**: 文档分割成小块

<div v-click="1">

- **Entity Recognition**: LLM识别每个块中的关键实体 (人、地、概念等)

</div>

<div v-click="2">

- **Relationship Extraction**: LLM识别实体间的关系，生成**实体-关系对**

</div>

<div v-click="3">

- **Knowledge Graph Construction**: 将实体-关系对构建成**图结构** (去重优化)

</div>

<div v-click="4">

- **Embedding Storage**: 将描述和关系转为向量，存入**向量数据库**

**默认向量数据库**: Nano Vector

</div>

---
page: 8

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["“检索”阶段，也就是当你问问题的时候，","LightRAG 就利用这个建好的知识图谱和向量数据库来找答案。","这也是 LightRAG 的一个亮点，它用的是“双层检索”（Dual-Level Retrieval）。","你想想，有时候你想知道一个非常具体的细节，","比如某项研究报告里的一个具体数字；","有时候你又想了解一个大的趋势，比如某个技术领域这几年的发展方向。","传统搜索可能顾此失彼。"],"en":["The 'Retrieval' phase, which is when you ask a question,","LightRAG uses the knowledge graph and vector database that have been built to find the answer.","This is also a highlight of LightRAG; it uses 'Dual-Level Retrieval'.","Think about it, sometimes you want to know a very specific detail,","like a particular number from a research report;","other times you want to understand a major trend, like the development direction of a certain tech field over the past few years.","Traditional search might struggle with this."]},"click1":{"zh_CN":["LightRAG 的双层检索就是为了解决这个问题。","它有一个“低层检索”（Local），","专门看图谱里问题相关的那些实体旁边有什么紧密连接的关系，","找到最精确、最具体的细节。"],"en":["LightRAG's dual-level retrieval is designed to solve this problem.","It has a 'Low-Level Retrieval',","specifically looking at the closely connected relationships near the entities related to your query in the graph,","finding the most precise and specific details."]},"click2":{"zh_CN":["同时还有一个“高层检索”（Global），它会看整个图谱，","找出和你的问题相关的那些大主题、大概念是什么，抓取的是更宏观的信息。"],"en":["At the same time, there is a 'High-Level Retrieval' (Global), which looks at the entire graph,","identifying the major themes and concepts related to your question, capturing more macroscopic information."]},"click3":{"zh_CN":["把这两者结合起来，你得到的答案就不光有细节事实，","还有更全面的背景和上下文，信息更完整。","所以，用 LightRAG 的结果就是，你得到的答案会更准、更快，","而且因为有增量更新的能力，即使信息在不断变化，","你的答案也能保持比较高的时效性和相关性。"],"en":["By combining these two, the answer you get doesn't just contain factual details,","but also broader context and background, making the information more complete.","So, the result of using LightRAG is that your answers will be more accurate and faster,","and because of the incremental update capability, even if information is constantly changing,","your answers can maintain a relatively high level of timeliness and relevance."]}}
---

# 2. 检索过程: 双层检索 (Local & Global)

- **核心**: 结合**局部细节**与**全局大图**来查找答案

<div v-click="1">

- **低层检索 (Local Retrieval)**:
    - 关注图谱中查询相关的**附近节点/关系**
    - swering **精确查询**，获取具体细节 (如某个统计数字)

</div>

<div v-click="2">

- **高层检索 (High-Level Retrieval)**:
    - 识别整个图谱中的** overarching themes and connections**
    - 获取 broader context 和 overarching 主题 (如趋势、发展方向)

</div>

<div v-click="3">

**结果**: 得到包含**事实**和**上下文**的**更完整**答案。

</div>

LightRAG 的双层检索就是为了解决这个问题。

---
page: 9

layout: two-cols
subtitles: {"default":{"zh_CN":["这对于需要快速、准确理解大量复杂信息的应用来说，特别有价值。","对了，关于怎么用起来，我看了下，我也是觉得挺方便的。","你可以直接从代码库克隆下来，或者用 pip 安装。","然后按照它提供的步骤，设置一下工作目录，","选择你想用的语言模型（它可以支持像 OpenAI 这样的，","然后把你的文档插进去（也就是完成索引过程），就可以开始问问题了。"],"en":["This is especially valuable for applications that require rapid and accurate understanding of large amounts of complex information.","Oh, by the way, regarding how to get started, I checked and it seems quite convenient.","You can clone it directly from the code repository or install it using pip.","Then, follow the steps provided to set up the working directory,","choose the language model you want to use (it supports ones like OpenAI),","and then insert your documents (which completes the indexing process), and you can start asking questions."]},"click1":{"zh_CN":["你在查询的时候，还可以选择不同的模式，","像只看细节的‘local’模式，看全局大图的‘global’模式，","或者两者结合的‘hybrid’模式，甚至还有‘naive’模式可以跟传统的 RAG 对比看看效果。","搭建过程很方便，请参考幻灯片上的代码。"],"en":["When querying, you can also choose different modes,","like the 'local' mode for focusing on details, the 'global' mode for the overall big picture,","or the 'hybrid' mode combining both, and even a 'naive' mode to compare with traditional RAG and see the difference.","The setup process is very convenient; please refer to the code on the slide."]},"click2":{"zh_CN":["这里的 param.mode 参数让你选择检索模式，你可以根据需要进行切换和测试。"],"en":["The param.mode parameter here allows you to choose the retrieval mode, you can switch and test according to your needs."]}}
---

# LightRAG 本地搭建指南 (使用 OpenAI 模型)

搭建过程很方便，请参考幻灯片上的代码。

1.  **克隆或安装**: 从 GitHub 克隆或使用 pip 安装
2.  **创建虚拟环境**: 使用 conda 或 virtualenv (推荐)
3.  **安装依赖**: `pip install -e .`

<div v-click="1">

4.  **索引与查询**: 运行 Python 代码进行索引和查询

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()
# import nest_asyncio 
# nest_asyncio.apply() 

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)

with open("./book.txt") as f:
    rag.insert(f.read())

# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))

# Perform local search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))

# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))

# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

</div>

<div v-click="2">

**查询模式 (param.mode)**:
- `naive`: 标准 RAG
- `local`: 基于实体邻域检索
- `global`: 更广泛的全局实体关系检索
- `hybrid`: 结合 local 和 global 模式

</div>

::right::



---
page: 10

layout: two-cols
subtitles: {"default":{"zh_CN":["也可以用 Ollama 这种可以在你本地跑的免费或开源模型，这个灵活性很赞！","也可以使用 Ollama 等本地模型，请参考幻灯片上的代码。"],"en":["You can also use free or open-source local models like Ollama, which offers great flexibility!","You can also use local models like Ollama; please refer to the code on the slide."]},"click1":{"zh_CN":["这段代码展示了如何配置 LightRAG 使用 Ollama 作为语言模型和嵌入模型，让你可以完全在本地运行。"],"en":["This code demonstrates how to configure LightRAG to use Ollama as both the language model and embedding model, allowing you to run it entirely locally."]}}
---

# LightRAG 本地搭建指南 (使用免费/私有模型 Ollama)

也可以使用 Ollama 等本地模型，请参考幻灯片上的代码。

<div v-click="1">

```python
import os

from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)

with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)

# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
)

# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)

# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```

</div>

::right::



---
page: 11

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["那这些技术对你有什么用呢？","想象一下，如果你平时需要阅读大量复杂的文档，","比如法律条文、研究报告、病历或者农业技术资料，","要快速找到关键信息和它们之间隐藏的联系是不是挺头疼的？"],"en":["So, how can these technologies be useful to you?","Imagine if you often need to read a large volume of complex documents,","such as legal texts, research reports, medical records, or agricultural technical data,","Doesn't it feel like a headache to quickly find key information and the hidden connections between them?"]},"click1":{"zh_CN":["LightRAG 这种能帮你自动构建关系网的工具，","在法律研究、医疗分析、这些领域，","都能帮你更高效、更准确地挖掘信息，","发现过去可能忽略的洞察。"],"en":["A tool like LightRAG, which can automatically help you build a relationship network,","In fields like legal research and medical analysis,","can help you extract information more efficiently and accurately,","and uncover insights that you might have previously overlooked."]},"click2":{"zh_CN":["它不只是帮你“找到”信息，","更是帮你“理解”信息背后的逻辑和关联。"],"en":["It doesn't just help you 'find' information,","it also helps you 'understand' the logic and connections behind the information."]},"click3":{"zh_CN":["我觉得这对于需要深入分析和理解文档内容的你来说，会是一个非常有用的工具。"],"en":["I think this will be a very useful tool for you, especially if you need to deeply analyze and understand document content."]}}
---

# LightRAG 的关键应用场景

适用于处理**复杂文档**或需要**基于实体分析**的领域:

<div v-click="1">

- **法律研究**: 提取法律、案例、判例间的关系

</div>

<div v-click="2">

- **医疗健康**: 分析病历、症状、治疗，发现医学见解

</div>

<div v-click="3">

- **农业**: 组织和检索作物、土壤、天气等信息

</div>

---
page: 12

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["总的来说，我理解 LightRAG 厉害的地方在于，","它把知识图谱和向量搜索结合起来，通过构建实体关系来理解文档，","这让它比传统 RAG 更懂上下文；"],"en":["Overall, what I understand makes LightRAG powerful is that","It combines knowledge graphs and vector search, and understands documents by building entity relationships,","This gives it a better grasp of context compared to traditional RAG;"]},"click1":{"zh_CN":["同时，它在实现上比 GraphRAG 更轻量、更省钱、更新更快，"],"en":["At the same time, its implementation is lighter, cheaper, and faster to update than GraphRAG,"]},"click2":{"zh_CN":["还有那个能兼顾细节和全局的双层检索。"],"en":["Plus, it has that dual-level retrieval that balances details and the overall picture."]},"click3":{"zh_CN":["我觉得，它确实代表了 RAG 技术的一个重要进步方向，"],"en":["I believe it truly represents a significant step forward for RAG technology,"]},"click4":{"zh_CN":["尤其是在处理大量复杂文档和需要快速响应的场景下，它的价值就非常突显了。"],"en":["Especially in scenarios involving large amounts of complex documents and requiring quick responses, its value becomes very apparent."]},"click5":{"zh_CN":["无论是处理海量数据还是需要智能、上下文感知响应，LightRAG 都是一个强大、开源的选择。"],"en":["Whether dealing with massive data or requiring intelligent, context-aware responses, LightRAG is a powerful, open-source option."]}}
---

# 结论: 为什么选择 LightRAG?

- **下一代 RAG**: 结合知识图谱与向量检索

<div v-click="1">

- **理解上下文**: 通过实体关系对更好地理解文档

</div>

<div v-click="2">

- **高效经济**: 比 GraphRAG 更轻量、成本更低

</div>

<div v-click="3">

- **实时性**: 支持增量更新，适应信息变化

</div>

<div v-click="4">

- **全面性**: 双层检索兼顾细节与全局

</div>

<div v-click="5">

无论是处理海量数据还是需要智能、上下文感知响应，LightRAG 都是一个强大、开源的选择。

</div>

---
page: 13

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["嗯，那听了这么多，结合你自己平时获取、管理信息的经验，","你觉得在哪些场景下，这种能理解‘关系’、能快速处理新信息的智能助手，","会给你带来最大的便利或者启发呢？","可以想想看。","好，今天就先聊到这儿。","谢谢你的时间！"],"en":["Okay, so after hearing all this, considering your own experience in acquiring and managing information,","in which scenarios do you think this kind of intelligent assistant, capable of understanding 'relationships' and quickly processing new information,","would bring you the greatest convenience or inspiration?","Feel free to think about it.","Alright, let's wrap up our discussion here for today.","Thank you for your time!"]}}
---

# 讨论与交流

- LightRAG 在哪些场景下能给你带来便利或启发？
- 你在处理复杂文档时遇到的主要挑战是什么？

谢谢大家的时间！