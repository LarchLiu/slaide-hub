---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "åœ¨ç¬”è®°æœ¬ä¸Šè¿è¡Œ1000äº¿å‚æ•°AIæ¨¡å‹ï¼šBitNet.cppçš„ç§˜å¯†"
titleTemplate: '%s - Slaide'
layout: cover
presenter: dev
seoMeta:
  ogTitle: "åœ¨ç¬”è®°æœ¬ä¸Šè¿è¡Œ1000äº¿å‚æ•°AIæ¨¡å‹ï¼šBitNet.cppçš„ç§˜å¯†"
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "ä¸­æ–‡(ç®€ä½“)"
  apiCustom:
    voice: 'rate:-0.2|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "äº‘é—´"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "æ™“æ™“"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["å“ˆå–½å¤§å®¶å¥½ï¼","ä»Šå¤©èŠçš„è¯é¢˜æœ‰ç‚¹åƒç§‘å¹»æˆçœŸäº†ã€‚","æƒ³è±¡ä¸€ä¸‹ï¼Œåœ¨ä½ è‡ªå·±çš„ç¬”è®°æœ¬ä¸Šï¼Œ","æ²¡æœ‰å‡ ä¸‡å—çš„æ˜¾å¡ï¼Œ","ä¸ç”¨ç§Ÿæ˜‚è´µçš„äº‘æœåŠ¡å™¨ï¼Œ","å°±é ä½ ç¬”è®°æœ¬é‡Œçš„CPUï¼Œ","èƒ½è·‘ä¸€ä¸ª1000äº¿å‚æ•°çš„å¤§å‹AIæ¨¡å‹ï¼","å¬èµ·æ¥æ˜¯ä¸æ˜¯æŒºå¤¸å¼ çš„ï¼Ÿ"],"en":["Hello everyone!","Today's topic is a bit like science fiction coming true.","Imagine this: on your own laptop,","without a graphics card that costs tens of thousands,","without renting expensive cloud servers,","just using the CPU inside your laptop,","you can run a large AI model with 100 billion parameters!","Doesn't that sound pretty exaggerated?"]}}
---

# ç”¨ç¬”è®°æœ¬è·‘1000äº¿å‚æ•°AIæ¨¡å‹ï¼Ÿ

## Microsoft BitNet.cpp å¦‚ä½•å®ç°

---
page: 2

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["ä½†å¾®è½¯æœ€è¿‘çœŸçš„æŠŠè¿™ä¸ªå˜æˆäº†ç°å®ï¼Œ","ä»–ä»¬å¼€æºäº†ä¸€ä¸ªå«åš BitNet.cpp çš„æ¡†æ¶ã€‚","æˆ‘è¯•äº†è¯•ï¼Œå½“æ—¶å°±æƒŠå‘†äº†ï¼","å®ƒä¸ä»…è®©è¿™æˆä¸ºå¯èƒ½ï¼Œ","è€Œä¸”è¿˜éå¸¸å¿«ï¼Œéå¸¸é«˜æ•ˆã€‚","ä¸ºä»€ä¹ˆè¯´è¿™ä¸ª BitNet.cpp è¿™ä¹ˆç‰›å‘¢ï¼Ÿ"],"en":["But Microsoft recently made this a reality.","They open-sourced a framework called BitNet.cpp.","I tried it, and I was absolutely stunned!","Not only does it make this possible,","but it's also incredibly fast and efficient.","So, why is this BitNet.cpp so impressive?"]}}
---

# BitNet.cpp: è®©AIæ¨¡å‹åœ¨CPUä¸Šé£è·ƒ

- Microsoft å¼€æºæ¡†æ¶
- å®ç°å¤§å‹AIæ¨¡å‹åœ¨CPUä¸Šé«˜æ•ˆè¿è¡Œ
- å¿«é€Ÿã€é«˜æ•ˆï¼Œæ”¹å˜AIåº”ç”¨æ¨¡å¼

![BitNet.cpp Logo](/bMI9j/e34a22f676079b3f8fc351814d7e70a7bdf8136f.webp)

---
page: 3

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["å°±åœ¨å‡ ä¸ªæ˜ŸæœŸå‰ï¼Œ","æˆ‘è¿˜åœ¨ç”¨ç¬”è®°æœ¬å€’è…¾å°å°çš„AIæ¨¡å‹ï¼Œ","æœºå™¨å°±å­å“§å­å“§åœ°å–˜ç²—æ°”ã€‚","æƒ³è·‘å¤§ä¸€ç‚¹çš„ï¼Ÿ","æ²¡é—¨å„¿ï¼Œå¾—ä¸Šäº‘ï¼Œå¾—èŠ±é’±ã€‚","ç»“æœæˆ‘çœ‹åˆ°äº† bitnet.cppï¼Œ","å“‡å¡ï¼Œæ„Ÿè§‰åƒæœ‰äººç»™æˆ‘å˜äº†ä¸ªé­”æ³•ã€‚","è¿™ä¸œè¥¿æœ€å¤§çš„äº®ç‚¹å°±æ˜¯ï¼š","ä¸éœ€è¦é«˜ç«¯ç¡¬ä»¶ï¼","ä½ çš„æ—¥å¸¸ç¬”è®°æœ¬æˆ–å°å¼æœºå°±èƒ½æå®šã€‚","å®Œå…¨ä¸ç”¨ä¸ºäº†è·‘AIå»å–è‚¾ä¹°æ˜¾å¡äº†ï¼Œå“ˆå“ˆã€‚"],"en":["Just a few weeks ago,","I was still fiddling with small AI models on my laptop,","and the machine was wheezing and struggling.","Want to run something bigger?","No way, you had to go to the cloud, and pay for it.","Then I saw BitNet.cpp,","Wow, it felt like someone performed magic for me.","The biggest highlight of this thing is:","No high-end hardware needed!","Your everyday laptop or desktop can handle it.","You absolutely don't need to sell a kidney to buy a graphics card for running AI anymore, haha."]},"click1":{"zh_CN":["è¿™ä¸œè¥¿æœ€å¤§çš„äº®ç‚¹å°±æ˜¯ï¼š","ä¸éœ€è¦é«˜ç«¯ç¡¬ä»¶ï¼","ä½ çš„æ—¥å¸¸ç¬”è®°æœ¬æˆ–å°å¼æœºå°±èƒ½æå®šã€‚","å®Œå…¨ä¸ç”¨ä¸ºäº†è·‘AIå»å–è‚¾ä¹°æ˜¾å¡äº†ï¼Œå“ˆå“ˆã€‚"],"en":["The biggest highlight of this is:","No high-end hardware required!","Your everyday laptop or desktop can handle it.","You definitely don't need to sell a kidney to buy a graphics card just to run AI anymore, haha."]}}
---

# å‘Šåˆ«ç¡¬ä»¶æŸç¼š

- **ç—›ç‚¹**: è·‘AIä¾èµ–æ˜‚è´µGPU/äº‘æœåŠ¡

<div v-click="1">

- **BitNet.cpp**: åœ¨æ™®é€šCPUä¸Šè¿è¡Œå¤§è§„æ¨¡æ¨¡å‹

![BitNet.cpp CPU Advantage](/bMI9j/64fa6163d0ae9f58cd49ef0865f481a7581d7ca3.webp)

</div>

---
page: 4

layout: two-cols
subtitles: {"default":{"zh_CN":["è€Œä¸”ï¼Œå®ƒçš„é€Ÿåº¦æå‡éå¸¸æƒŠäººï¼š"],"en":["Moreover, its speed improvement is astonishing:"]},"click1":{"zh_CN":["åœ¨ ARM æ¶æ„çš„ CPU ä¸Šï¼Œ","é€Ÿåº¦èƒ½æå‡ 1.37åˆ°5.07å€ã€‚","åœ¨ x86 æ¶æ„çš„ CPU ä¸Šï¼Œ","æ›´æ˜¯èƒ½é£™åˆ° 2.37åˆ°6.17å€ï¼","è€Œä¸”æ¨¡å‹è¶Šå¤§ï¼Œæé€Ÿè¶Šæ˜æ˜¾ã€‚"],"en":["On ARM-based CPUs,","the speed can increase by 1.37 to 5.07 times.","On x86-based CPUs,","it can even soar to 2.37 to 6.17 times!","And the larger the model, the more significant the speed boost."]},"click2":{"zh_CN":["æ›´å‰å®³çš„æ˜¯ï¼Œå®ƒè¿˜è¶…çº§çœç”µï¼š","èƒ½èŠ‚çœ 55.4%åˆ°82.2%çš„èƒ½æºæ¶ˆè€—ã€‚","è¿™ä¸ä»…å¸®ä½ çœç”µè´¹ï¼Œå¯¹åœ°çƒä¹Ÿæ›´å‹å¥½ã€‚"],"en":["What's more impressive is that it's incredibly power-efficient:","It can save 55.4% to 82.2% of energy consumption.","This not only saves you electricity bills but is also friendlier to the planet."]},"click3":{"zh_CN":["è¿˜æœ‰ä¸€ä¸ªç‚¹æˆ‘ç‰¹åˆ«å–œæ¬¢ï¼Œå°±æ˜¯éšç§æ€§ã€‚","å› ä¸ºæ¨¡å‹å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œï¼Œ","ä½ çš„æ•°æ®å°±ä¸ç”¨ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œ","æ›´å®‰å…¨ï¼Œæ›´æ”¾å¿ƒã€‚"],"en":["Another point I particularly like is privacy.","Because the model can run locally,","your data doesn't need to be uploaded to the cloud,","making it safer and more secure."]},"click4":{"zh_CN":["è€Œä¸”å®ƒçœŸçš„èƒ½å¤„ç†å¤§å‹å·çš„æ¨¡å‹ã€‚","æˆ‘è·‘äº†ä¸€ä¸‹é‚£ä¸ª1000äº¿å‚æ•°çš„æ¨¡å‹ï¼Œ","å®ƒè¾“å‡ºæ–‡æœ¬çš„é€Ÿåº¦å¤§æ¦‚æ¯ç§’5-7ä¸ªè¯ï¼Œ","å·®ä¸å¤šå°±æ˜¯ä½ æˆ‘å¹³æ—¶è¯»é‚®ä»¶çš„é€Ÿåº¦ï¼Œ","æ„Ÿè§‰å°±åƒè·Ÿä¸€ä¸ªçœŸäººèŠå¤©ä¸€æ ·ï¼Œéå¸¸å®ç”¨ã€‚"],"en":["And it can really handle large models.","I ran the 100 billion parameter model,","and its text output speed is about 5-7 words per second,","which is roughly the speed you and I read emails,","It feels just like chatting with a real person, very practical."]}}
---

# BitNet.cpp æ ¸å¿ƒä¼˜åŠ¿

- **æ— éœ€é«˜ç«¯ç¡¬ä»¶**: åˆ©ç”¨ç°æœ‰CPU

<div v-click="1">

- **é€Ÿåº¦æƒŠäºº**:
  - ARM CPU: 1.37x - 5.07x æ›´å¿«
  - x86 CPU: 2.37x - 6.17x æ›´å¿« (æ¨¡å‹è¶Šå¤§æå‡è¶Šæ˜æ˜¾)

</div>

<div v-click="2">

- **èƒ½æ•ˆæ¯”é«˜**: èŠ‚çœ 55.4% - 82.2% èƒ½æº

</div>

<div v-click="3">

- **æ•°æ®éšç§**: æœ¬åœ°ç¦»çº¿è¿è¡Œ

</div>

<div v-click="4">

- **æ”¯æŒå¤§å‹æ¨¡å‹**: 100Bå‚æ•°æ¨¡å‹ï¼Œæ¯ç§’5-7è¯è¾“å‡º

</div>

::right::



---
page: 5

layout: two-cols
subtitles: {"default":{"zh_CN":["è¿™åˆ°åº•æ˜¯æ€ä¹ˆåšåˆ°çš„å‘¢ï¼Ÿ","è¯´åˆ°æŠ€æœ¯åŸç†ï¼Œ","BitNet.cpp ä¸“é—¨ç”¨æ¥è¿è¡Œ 1-bit å¤§è¯­è¨€æ¨¡å‹ã€‚","æ¯”å¦‚é‚£ä¸ª BitNet b1.58 æ¨¡å‹ã€‚","ä¼ ç»Ÿçš„AIæ¨¡å‹å°±åƒé‚£äº›å¤§å‹SUVï¼Œ","å¼ºåŠ²ä½†åˆé‡åˆè´¹æ²¹ï¼Œ","éœ€è¦ç”¨å¤§å—å¤´çš„æ•°æ®æ¥å­˜å‚¨çŸ¥è¯†ï¼Œ","éå¸¸å ç”¨å†…å­˜ï¼Œä¹Ÿéœ€è¦ç‰¹åˆ«å¼ºçš„ç¡¬ä»¶ã€‚"],"en":["So, how is this actually done?","Speaking of the technical principles,","BitNet.cpp is specifically designed to run 1-bit large language models.","For example, the BitNet b1.58 model.","Traditional AI models are like those large SUVs,","powerful but heavy and fuel-hungry,","requiring large chunks of data to store knowledge,","taking up a lot of memory and needing particularly strong hardware."]},"click1":{"zh_CN":["è€Œ BitNet.cpp é…åˆçš„1-bitæ¨¡å‹å‘¢ï¼Œ","å°±åƒä¸€ä¸ªè½»å·§çµæ´»çš„ç”µåŠ¨æ»‘æ¿è½¦ã€‚","å®ƒç”¨äº†ä¸ªå« 1.58-bit é‡åŒ–çš„æŠ€æœ¯ã€‚","ç†è§£æˆä¸€ç§è¶…çº§å‹ç¼©æ–¹æ³•ï¼Œ","æŠŠæ¨¡å‹é‡Œå¤æ‚çš„æ•°å­—éƒ½å˜æˆäº†æœ€ç®€å•çš„ -1ã€0ã€1ã€‚","è¿™ä¸€ä¸‹å°±æŠŠæ¨¡å‹ä½“ç§¯å¤§å¤§ç¼©å°äº†ï¼Œ","å°åˆ°ä½ çš„CPUéƒ½èƒ½è½»æ¾æ¬åŠ¨ï¼Œå¤„ç†èµ·æ¥æ¯«ä¸è´¹åŠ›ã€‚"],"en":["And the 1-bit model paired with BitNet.cpp,","is like a light and nimble electric scooter.","It uses a technique called 1.58-bit quantization.","Think of it as a super compression method,","which turns the complex numbers inside the model into the simplest -1, 0, and 1.","This significantly shrinks the model size,","so small that your CPU can easily move and process it without effort."]},"click2":{"zh_CN":["è€Œä¸”ï¼Œè¿™ä¸ªæ¡†æ¶é‡Œè¿˜æœ‰å¾ˆå¤šä¼˜åŒ–è¿‡çš„æ ¸å¿ƒä»£ç ã€‚","è¿™äº›å°±åƒç»™æ»‘æ¿è½¦çš„é©¬è¾¾åšäº†ç‰¹åˆ«è°ƒæ ¡ï¼Œ","è®©å®ƒåœ¨ä½ çš„CPUä¸Šä¹Ÿèƒ½è·‘å¾—é£å¿«ï¼Œ","è€Œä¸”ä¸æµªè´¹èƒ½é‡ã€‚"],"en":["Furthermore, there are many optimized core codes in this framework.","These are like specially tuned motors for the scooter,","allowing it to run very fast on your CPU,","and without wasting energy."]},"click3":{"zh_CN":["è™½ç„¶ç›®å‰å®ƒä¸»è¦èšç„¦åœ¨CPUä¸Šï¼Œ","ä½†æœªæ¥ä¹Ÿä¼šæ”¯æŒNPUå’ŒGPUã€‚","ä¸è¿‡å°±ç›®å‰æ¥çœ‹ï¼Œ","å·²ç»è¶³ä»¥è®©ä½ çš„æ™®é€šç”µè„‘å˜æˆAIå°è¶…äººäº†ã€‚","è¿™é¡¹æŠ€æœ¯å¸¦æ¥çš„å¯èƒ½æ€§ä¹Ÿå¾ˆå¤šï¼š","æ¯”å¦‚å¯ä»¥åœ¨æ²¡ç½‘æ—¶ç”¨çš„ç¦»çº¿è¯­éŸ³åŠ©æ‰‹ã€","è®©AIè·‘åœ¨å„ç§å°å‹è®¾å¤‡ä¸Šï¼Œ","è¿˜æœ‰å°±æ˜¯åˆšæ‰è¯´çš„ï¼Œæ›´ç¯ä¿çš„AIã€‚"],"en":["Although currently it mainly focuses on the CPU,","it will also support NPUs and GPUs in the future.","However, as it stands now,","it's already enough to turn your ordinary computer into a little AI superhero.","The possibilities brought by this technology are also numerous:","For example, offline voice assistants that work without internet,","running AI on various small devices,","and as I just mentioned, more environmentally friendly AI."]}}
---

# æŠ€æœ¯æ ¸å¿ƒï¼š1-bit LLMs ä¸é‡åŒ–

- **ä¼ ç»Ÿæ¨¡å‹**: ä½¿ç”¨16/32ä½æ•°æ®ï¼Œä½“ç§¯åºå¤§ï¼Œç¡¬ä»¶éœ€æ±‚é«˜ (ç±»æ¯”: å¤§å‹SUV)

<div v-click="1">

- **BitNet.cpp + 1-bit LLM (å¦‚ BitNet b1.58)**:
  - ä½¿ç”¨ **1.58-bit é‡åŒ–**: æ•°æ®å‹ç¼©åˆ° -1, 0, 1
  - æ¨¡å‹ä½“ç§¯å¤§å¹…ç¼©å° (ç±»æ¯”: ç”µåŠ¨æ»‘æ¿è½¦)

</div>

<div v-click="2">

- **ä¼˜åŒ–è¿‡çš„æ ¸å¿ƒä»£ç  (Kernels)**: ä¸“ä¸ºCPUä¼˜åŒ–è®¡ç®—

</div>

<div v-click="3">

- **ç›®æ ‡**: CPUä¼˜å…ˆï¼Œæœªæ¥æ”¯æŒNPU/GPU

</div>

::right::



---
page: 6

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["å¥½äº†ï¼Œå…‰è¯´ä¸ç»ƒå‡æŠŠå¼ï¼","æƒ³ä¸æƒ³äº²æ‰‹è¯•è¯•ï¼Ÿ","æˆ‘ç°åœ¨å°±æ¥å¸¦ä½ ä¸€èµ·ä¸Šæ‰‹ã€‚","æ”¾å¿ƒï¼Œæ²¡ä½ æƒ³çš„é‚£ä¹ˆéš¾ï¼Œ","æˆ‘å°½é‡ç”¨æœ€ç®€å•çš„æ–¹å¼è·Ÿä½ è¯´ï¼Œ","å°±åƒç»™æˆ‘éæŠ€æœ¯è¡¨å¼Ÿè§£é‡Šä¸€æ ·ï¼Œå“ˆå“ˆã€‚"],"en":["Okay, talking without doing is just empty talk!","Do you want to try it yourself?","I'll walk you through getting started right now.","Don't worry, it's not as hard as you might think,","I'll try to explain it in the simplest way possible,","like explaining it to my non-tech cousin, haha."]}}
---

# äº²æ‰‹å®è·µï¼šä¸Šæ‰‹æŒ‡å—

---
page: 7

layout: two-cols
subtitles: {"default":{"zh_CN":["ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å·¥å…·","ä½ éœ€è¦è£…å‡ ä¸ªä¸œè¥¿ã€‚","åˆ«æ€•ï¼Œéƒ½å¾ˆåŸºç¡€ï¼š","Python: 3.9ç‰ˆæœ¬æˆ–æ›´æ–°çš„ã€‚","CMake: 3.22ç‰ˆæœ¬æˆ–æ›´é«˜çš„ã€‚","å®ƒåƒä¸ªä¸‡èƒ½èƒ¶ï¼Œèƒ½å¸®ä½ æŠŠä»£ç ç¼–è¯‘èµ·æ¥ã€‚","Clang: 18ç‰ˆæœ¬æˆ–æ›´é«˜çš„ã€‚","è¿™æ˜¯ä¸ªç¼–è¯‘å™¨ã€‚","Conda (å¯é€‰): æˆ‘ä¸ªäººå¾ˆæ¨èç”¨å®ƒã€‚","èƒ½å¸®ä½ æŠŠPythonç¯å¢ƒç®¡ç†å¾—å¹²å¹²å‡€å‡€ã€‚"],"en":["Step 1: Prepare the Tools","You need to install a few things.","Don't worry, they are all basic:","Python: version 3.9 or newer.","CMake: version 3.22 or higher.","It's like a universal glue that helps compile your code.","Clang: version 18 or higher.","This is a compiler.","Conda (Optional): I personally highly recommend using it.","It can help you keep your Python environment neat and clean."]},"click1":{"zh_CN":["Windows çš„æœ‹å‹ä»¬æ³¨æ„å•¦ï¼š","ä½ éœ€è¦å®‰è£… Visual Studio 2022ã€‚","å®‰è£…æ—¶è®°å¾—å‹¾é€‰è¿™äº›é€‰é¡¹ï¼š","ä½¿ç”¨ C++ çš„æ¡Œé¢å¼€å‘","é€‚ç”¨äº Windows çš„ C++ CMake å·¥å…·","Git for Windows","é€‚ç”¨äº Windows çš„ C++ Clang ç¼–è¯‘å™¨","MSBuild Support for LLVM-Toolset (clang)","ä¹‹åæ‰€æœ‰å‘½ä»¤è¡Œæ“ä½œï¼Œ","æœ€å¥½éƒ½åœ¨ Developer Command Prompt æˆ– PowerShell for VS2022 é‡Œè¿›è¡Œã€‚","èƒ½çœå»ä¸å°‘éº»çƒ¦ã€‚"],"en":["Attention Windows users:","You need to install Visual Studio 2022.","Remember to check these options during installation:","Desktop development with C++","C++ CMake Tools for Windows","Git for Windows","C++ Clang Compiler for Windows","MSBuild Support for LLVM-Toolset (clang)","After that, all command-line operations,","are best done in the Developer Command Prompt or PowerShell for VS2022.","It can save a lot of trouble."]},"click2":{"zh_CN":["Linux (æ¯”å¦‚ Debian æˆ– Ubuntu) çš„æœ‹å‹ï¼š","å¯ä»¥ç›´æ¥è¿è¡Œä¸‹é¢è¿™è¡Œå‘½ä»¤æ¥å®‰è£… Clangï¼š","bash -c \"$(wget -O - https://apt.llvm.org/llvm.sh)\"","æ­£å¼å¼€å§‹ç¼–è¯‘é¡¹ç›®å‰ï¼Œ","å¯ä»¥å…ˆè·‘ä¸€ä¸‹ `clang -v` æ¥ç¡®è®¤ Clang è£…å¥½äº†ã€‚","Windows ç”¨æˆ·ä¹Ÿè¦ç¡®è®¤èƒ½åœ¨ VS2022 çš„å‘½ä»¤è¡Œç¯å¢ƒé‡Œè®¿é—®åˆ°å®ƒä»¬ã€‚"],"en":["For Linux users (like Debian or Ubuntu):","You can directly run the following command to install Clang:","bash -c \"$(wget -O - https://apt.llvm.org/llvm.sh)\"","Before starting the project compilation,","you can run `clang -v` to confirm that Clang is installed.","Windows users also need to confirm that they can access them in the VS2022 command-line environment."]}}
---

## Step 1: å‡†å¤‡å·¥å…·

- **Python**: 3.9+
- **CMake**: 3.22+
- **Clang**: 18+
- **Conda** (æ¨è): ç®¡ç†Pythonç¯å¢ƒ

<div v-click="1">

**Windows (éœ€å®‰è£… Visual Studio 2022 å¹¶å‹¾é€‰):**
- Desktop development with C++
- C++ CMake Tools for Windows
- Git for Windows
- C++ Clang Compiler for Windows
- MSBuild Support for LLVM-Toolset (clang)
*ä½¿ç”¨ `Developer Command Prompt` æˆ– `PowerShell for VS2022`*

</div>

<div v-click="2">

**Linux (Debian/Ubuntu):**
```bash
bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"
```

*éªŒè¯å®‰è£…: `clang -v`*

</div>

::right::



---
page: 8

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["ç¬¬äºŒæ­¥ï¼šæŠŠä»£ç â€œ snag â€ä¸‹æ¥","ä» GitHub ä¸ŠæŠŠ bitnet.cpp çš„ä»£ç ä¸‹è½½åˆ°ä½ çš„ç”µè„‘ã€‚","æ‰“å¼€ç»ˆç«¯ï¼Œè¾“å…¥ï¼š","git clone --recursive https://github.com/microsoft/BitNet.git","cd BitNet"],"en":["Step 2: 'Snag' the Code","Download the BitNet.cpp code from GitHub to your computer.","Open your terminal and enter:","git clone --recursive https://github.com/microsoft/BitNet.git","cd BitNet"]}}
---

## Step 2: å…‹éš†ä»£ç 

æ‰“å¼€ç»ˆç«¯æˆ– PowerShellï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
```

---
page: 9

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["ç¬¬ä¸‰æ­¥ï¼šæ­å»ºç¯å¢ƒ","å¦‚æœä½ ç”¨ Condaï¼š","conda create -n bitnet-cpp python=3.9","conda activate bitnet-cpp","pip install -r requirements.txt"],"en":["Step 3: Set up the Environment","If you are using Conda:","conda create -n bitnet-cpp python=3.9","conda activate bitnet-cpp","pip install -r requirements.txt"]},"click1":{"zh_CN":["å¦‚æœä½ ä¸ç”¨ Condaï¼Œ","ç¡®ä¿å½“å‰ Python ç¯å¢ƒé‡Œè£…å¥½äº† requirements.txt é‡Œçš„åº“å°±è¡Œã€‚"],"en":["If you are not using Conda,","just make sure your current Python environment meets the requirements in requirements.txt."]}}
---

## Step 3: è®¾ç½®ç¯å¢ƒ (æ¨èä½¿ç”¨ Conda)

```bash
# åˆ›å»ºå¹¶æ¿€æ´»æ–°ç¯å¢ƒ
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

<div v-click="1">

*å¦‚æœä¸ç”¨Condaï¼Œè¯·ç¡®ä¿å½“å‰Pythonç¯å¢ƒæ»¡è¶³`requirements.txt`è¦æ±‚*

</div>

---
page: 10

layout: two-cols
subtitles: {"default":{"zh_CN":["ç¬¬å››æ­¥ï¼šä¸‹è½½ä¸€ä¸ªæ¨¡å‹","ä½ å¯ä»¥ä» HuggingFace ä¸Šä¸‹è½½é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ã€‚","æˆ‘è¯•äº† BitNet-b1.58â€“2B-4T è¿™ä¸ªæ¨¡å‹ï¼Œå¾ˆé€‚åˆå…¥é—¨æµ‹è¯•ï¼š","huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T"],"en":["Step 4: Download a Model","You can download a pre-trained model file from HuggingFace.","I tried the BitNet-b1.58â€“2B-4T model, which is great for getting started:","huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T"]},"click1":{"zh_CN":["ä¸‹è½½ä¸‹æ¥ä¹‹åï¼Œ","ä½ éœ€è¦ç”¨ä¸€ä¸ªè„šæœ¬æ¥è®¾ç½®ä¸€ä¸‹ç¯å¢ƒï¼Œ","å¹¶æŒ‡å®šæ¨¡å‹çš„ç›®å½•å’Œé‡åŒ–ç±»å‹ï¼š","python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s","setup_env.py çš„ Usage è¯´æ˜é‡Œï¼Œ","æœ‰å¾ˆå¤šå¯é€‰çš„æ¨¡å‹ä»“åº“å’Œé‡åŒ–ç±»å‹å¯ä»¥ç©ã€‚","-md å°±æ˜¯æŒ‡å®šæ¨¡å‹çš„æœ¬åœ°ç›®å½•ï¼Œ-q æ˜¯é‡åŒ–ç±»å‹ã€‚"],"en":["After downloading it,","you need to use a script to set up the environment,","and specify the model directory and quantization type:","python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s","In the Usage instructions for setup_env.py,","there are many optional model repositories and quantization types to experiment with.","-md specifies the local model directory, and -q is the quantization type."]}}
---

## Step 4: ä¸‹è½½æ¨¡å‹

ä» HuggingFace ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¾‹å¦‚ BitNet-b1.58â€“2B-4T:

```bash
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
```


::right::


<div v-click="1">

ç„¶åè¿è¡Œ `setup_env.py` é…ç½®ç¯å¢ƒï¼š

```bash
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s
```

*`-md`: æ¨¡å‹æœ¬åœ°ç›®å½•ï¼Œ`-q`: é‡åŒ–ç±»å‹ã€‚æ›´å¤šé€‰é¡¹è¯·å‚è€ƒ `setup_env.py -h`*

</div>

---
page: 11

layout: two-cols
subtitles: {"default":{"zh_CN":["ç¬¬äº”æ­¥ï¼šè¿è¡ŒAIé­”æ³•ï¼","ç°åœ¨ï¼Œè¯¥è®©AIåŠ¨èµ·æ¥äº†ï¼","å…ˆè®¾ç½®å¥½ç¯å¢ƒï¼Œç„¶åè¿è¡Œæ¨ç†è„šæœ¬ï¼š","python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s","python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p \"You're my trusty AI sidekick\" -cnv","è¿™è¡Œå‘½ä»¤ä¼šè®©æ¨¡å‹è¿›å…¥èŠå¤©æ¨¡å¼ï¼Œ","å¹¶ä¸”ä»¥ \"You're my trusty AI sidekick\" ä½œä¸ºå¼€åœºç™½ã€‚"],"en":["Step 5: Run the AI Magic!","Now, it's time to get the AI running!","First, set up the environment, then run the inference script:","python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s","python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p \"You're my trusty AI sidekick\" -cnv","This command will put the model into chat mode,","and use \"You're my trusty AI sidekick\" as the opening prompt."]},"click1":{"zh_CN":["ä½ å¯ä»¥åœ¨å‘½ä»¤åé¢åŠ ä¸€äº›å‚æ•°æ¥è°ƒæ•´ï¼š","-n: æ§åˆ¶æ¨¡å‹ç”Ÿæˆå¤šå°‘ä¸ªè¯ã€‚","-t: ç”¨å¤šå°‘ä¸ª CPU çº¿ç¨‹æ¥è·‘ã€‚","-temp: æ§åˆ¶AIå›å¤çš„â€œè„‘æ´â€å¤§å°ã€‚"],"en":["You can add some parameters after the command to adjust:","-n: Controls how many tokens the model generates.","-t: Specifies how many CPU threads to use.","-temp: Controls the 'creativity' or randomness of the AI's response."]},"click2":{"zh_CN":["å¦‚æœä½ è·‘æˆåŠŸäº†ï¼Œå¯èƒ½ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„è¾“å‡ºï¼š","Yo, Iâ€™m your AI sidekick! Ready to answer questions, crack jokes, or maybe write a poem? Whatâ€™s up?","æ„Ÿè§‰å°±åƒçœŸçš„æœ‰ä¸ªæœºå™¨äººåŠ©æ‰‹ååœ¨ä½ ç”µè„‘é‡Œè·Ÿä½ æ‰“æ‹›å‘¼ï¼","è€Œä¸”è¿™ä¸€åˆ‡éƒ½æ˜¯ä½ çš„CPUåœ¨é»˜é»˜å®Œæˆã€‚"],"en":["If you run it successfully, you might see output like this:","Yo, Iâ€™m your AI sidekick! Ready to answer questions, crack jokes, or maybe write a poem? Whatâ€™s up?","It feels like you really have a robot assistant sitting in your computer greeting you!","And all of this is being quietly done by your CPU."]}}
---

## Step 5: è¿è¡Œæ¨ç† (AIå¯¹è¯!)

è®¾ç½®ç¯å¢ƒåï¼Œè¿è¡Œ `run_inference.py`:

```bash
# ç¤ºä¾‹ï¼šä»¥èŠå¤©æ¨¡å¼å¯åŠ¨
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You're my trusty AI sidekick" -cnv
```

<div v-click="1">

**å¸¸ç”¨å‚æ•°:**
- `-n`: ç”Ÿæˆtokensæ•°é‡
- `-t`: ä½¿ç”¨CPUçº¿ç¨‹æ•°
- `-temp`: æ§åˆ¶å›å¤éšæœºæ€§ (å¦‚ 0.7)

</div>

<div v-click="2">

**ç¤ºä¾‹è¾“å‡º:**
```text
Yo, Iâ€™m your AI sidekick! Ready to answer questions, crack jokes, or maybe write a poem? Whatâ€™s up?
```

</div>

::right::



---
page: 12

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["ç¬¬å…­æ­¥ï¼šæµ‹æµ‹é€Ÿåº¦å¤šå¿«","å¦‚æœä½ å¥½å¥‡è‡ªå·±çš„æœºå™¨èƒ½è·‘å¤šå¿«ï¼Œ","å¯ä»¥è·‘ä¸ªåŸºå‡†æµ‹è¯•ï¼š","python utils/e2e_benchmark.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -n 200 -p 256 -t 4","è¿™ä¸ªå‘½ä»¤ä¼šç”¨256è¯çš„æç¤ºè¯­ï¼Œ","è®©æ¨¡å‹ç”Ÿæˆ200ä¸ªè¯ï¼Œå¹¶ç”¨4ä¸ªCPUçº¿ç¨‹ã€‚","è·‘å®Œä¹‹åï¼Œå®ƒä¼šå‘Šè¯‰ä½ é€Ÿåº¦å’Œèƒ½è€—ç­‰ä¿¡æ¯ã€‚","æˆ‘è·‘çš„æ—¶å€™ï¼Œçœ‹åˆ°æˆ‘çš„æ—§ç¬”è®°æœ¬","ç«Ÿç„¶èƒ½æ¯”æˆ‘æ‰“å­—è¿˜å¿«åœ°è¾“å‡ºæ–‡æœ¬ï¼ŒçœŸæ˜¯æŒºéœ‡æ’¼çš„ï¼"],"en":["Step 6: Test the Speed","If you're curious how fast your machine can run,","you can run a benchmark test:","python utils/e2e_benchmark.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -n 200 -p 256 -t 4","This command will use a 256-token prompt,","ask the model to generate 200 tokens, and use 4 CPU threads.","After running, it will tell you information like speed and energy consumption.","When I ran it, seeing my old laptop","outputting text faster than I could type was truly impressive!"]}}
---

## Step 6: æ€§èƒ½åŸºå‡†æµ‹è¯•

æƒ³çŸ¥é“ä½ çš„æœºå™¨æœ‰å¤šå¿«ï¼Ÿè¿è¡ŒåŸºå‡†æµ‹è¯•è„šæœ¬ï¼š

```bash
python utils/e2e_benchmark.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -n 200 -p 256 -t 4
```

*ä½¿ç”¨256è¯æç¤ºï¼Œç”Ÿæˆ200è¯ï¼Œç”¨4çº¿ç¨‹ã€‚æ˜¾ç¤ºé€Ÿåº¦ã€èƒ½è€—ç­‰ç»Ÿè®¡ä¿¡æ¯*

---
page: 13

layout: two-cols
subtitles: {"default":{"zh_CN":["å°å½©è›‹ï¼šç©ç©â€œå‡â€æ¨¡å‹","å¦‚æœä½ åªæƒ³æµ‹è¯•æ¡†æ¶ï¼Œä¸æƒ³ä¸‹è½½å¤§æ¨¡å‹ï¼Œ","è¿˜å¯ä»¥åˆ›å»ºä¸€ä¸ªå‡çš„ï¼ˆdummyï¼‰æ¨¡å‹æ¥ç©ï¼š","python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M"],"en":["Little Bonus: Play with a 'Dummy' Model","If you just want to test the framework and don't want to download a large model,","you can also create a dummy model to play with:","python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M"]},"click1":{"zh_CN":["è¿™ä¼šç”Ÿæˆä¸€ä¸ª1.25äº¿å‚æ•°çš„å‡æ¨¡å‹ï¼Œ","ç„¶åä½ å¯ä»¥ç”¨å®ƒæ¥è·‘åŸºå‡†æµ‹è¯•ã€‚","python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128","è¿™ä¸ªåŠŸèƒ½å¾ˆé€‚åˆå¿«é€ŸéªŒè¯æŸä¸ªå‚æ•°è®¾ç½®æˆ–æµ‹è¯•æ¡†æ¶æµç¨‹ã€‚"],"en":["This will generate a dummy model with 125 million parameters,","and then you can use it to run benchmark tests.","python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128","This feature is great for quickly verifying a certain parameter setting or testing the framework process."]}}
---

## ğŸ’¡ å½©è›‹: ç©è½¬è™šæ‹Ÿæ¨¡å‹ (Dummy Model)

ä¸ä¸‹è½½å®Œæ•´å¤§æ¨¡å‹ï¼Œä¹Ÿèƒ½æµ‹è¯•æ¡†æ¶ï¼š

```bash
# ç”Ÿæˆä¸€ä¸ª1.25äº¿å‚æ•°çš„è™šæ‹Ÿæ¨¡å‹
python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M
```


::right::


<div v-click="1">

# å¯¹è™šæ‹Ÿæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•

```bash
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
```

*é€‚åˆå¿«é€ŸéªŒè¯é…ç½®å’Œæ¡†æ¶æµç¨‹*

</div>

---
page: 14

layout: two-cols
subtitles: {"default":{"zh_CN":["æ€»çš„æ¥è¯´ï¼ŒBitNet.cpp è¿™ä¸ªé¡¹ç›®ï¼Œ"],"en":["In summary, the BitNet.cpp project,"]},"click1":{"zh_CN":["é€šè¿‡ 1.58-bit é‡åŒ–å’Œåº•å±‚ä¼˜åŒ–ï¼Œ"],"en":["through 1.58-bit quantization and low-level optimization,"]},"click2":{"zh_CN":["æŠŠä¹‹å‰åªèƒ½åœ¨é«˜ç«¯ç¡¬ä»¶ä¸Šè¿è¡Œçš„å¤§å‹AIæ¨¡å‹ï¼Œ","â€œæ¬â€åˆ°äº†æˆ‘ä»¬æ™®é€šäººæ‰‹é‡Œçš„ç”µè„‘ä¸Šã€‚"],"en":["has 'moved' large AI models that previously could only run on high-end hardware,","onto the computers in the hands of ordinary people."]},"click3":{"zh_CN":["è¿™ä¸ä»…ä»…æ˜¯æŠ€æœ¯ä¸Šçš„çªç ´ï¼Œ","å®ƒæ‰“ç ´äº†ç¡¬ä»¶å£å’ï¼Œé™ä½äº†AIåº”ç”¨çš„é—¨æ§›ã€‚"],"en":["This is not just a technical breakthrough,","it breaks down hardware barriers and lowers the threshold for AI applications."]},"click4":{"zh_CN":["æ¨åŠ¨äº†AIçš„æ™®åŠä¸åˆ›æ–°"],"en":["promoting the popularization and innovation of AI"]},"click5":{"zh_CN":["è®©å¼ºå¤§çš„AIèƒ½åŠ›å˜å¾—è§¦æ‰‹å¯åŠï¼Œ","ä¹Ÿä¸ºAIçš„æ™®åŠå’Œåˆ›æ–°æ‰“å¼€äº†æ–°çš„å¤§é—¨ã€‚"],"en":["making powerful AI capabilities within reach,","and opening up new doors for AI's widespread adoption and innovation."]}}
---

# æ€»ç»“ï¼šAIæ°‘ä¸»åŒ–è¿›ç¨‹

<div v-click="1">

- BitNet.cpp é€šè¿‡ 1.58-bit é‡åŒ–å’Œåº•å±‚ä¼˜åŒ–

</div>

<div v-click="2">

- å°†å¤§å‹AIæ¨¡å‹â€œæ¬â€åˆ°æ™®é€šPCçš„CPUä¸Š

</div>

<div v-click="3">

- æ‰“ç ´ç¡¬ä»¶å£å’ï¼Œé™ä½AIåº”ç”¨é—¨æ§›

</div>

<div v-click="4">

- æ¨åŠ¨AIæ™®åŠä¸åˆ›æ–°

</div>

<div v-click="5">

**å¼ºå¤§AIèƒ½åŠ›ï¼Œè§¦æ‰‹å¯åŠï¼**

</div>

::right::



---
page: 15

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["å¥½å•¦ï¼Œå…³äºå¾®è½¯çš„ BitNet.cpp","å’Œå¦‚ä½•åœ¨ä½ çš„ç¬”è®°æœ¬ä¸Šè·‘å¤§å‹AIæ¨¡å‹ï¼Œ","æˆ‘å°±åˆ†äº«åˆ°è¿™é‡Œã€‚","é‚£ä¹ˆï¼Œå¦‚æœç°åœ¨ä½ çš„ç¬”è®°æœ¬å°±èƒ½è·‘ä¸€ä¸ª1000äº¿å‚æ•°çš„AIæ¨¡å‹ï¼Œ","ä½ ä¼šç”¨å®ƒæ¥åšç‚¹ä»€ä¹ˆå‘¢ï¼Ÿ"],"en":["Alright, that concludes my sharing about Microsoft's BitNet.cpp","and how to run large AI models on your laptop.","So, if your laptop could now run a 100 billion parameter AI model,","what would you use it for?"]},"click1":{"zh_CN":["æ„Ÿè°¢ä½ çš„æ”¶å¬ï¼","å¦‚æœä½ å°è¯•äº†æˆ–è€…æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Œæ¬¢è¿ç•™è¨€å‘Šè¯‰æˆ‘ï¼"],"en":["Thank you for listening!","If you've tried it or have any thoughts, feel free to leave a comment and let me know!"]}}
---

# äº¤æµä¸åˆ†äº«

å¦‚æœä½ çš„ç¬”è®°æœ¬å°±èƒ½è·‘ä¸€ä¸ª1000äº¿å‚æ•°çš„AIæ¨¡å‹ï¼Œ
ä½ ä¼šç”¨å®ƒæ¥åšç‚¹ä»€ä¹ˆå‘¢ï¼Ÿ

<div v-click="1">

**æ„Ÿè°¢æ”¶å¬ï¼**
**æ¬¢è¿ç•™è¨€åˆ†äº«ä½ çš„æƒ³æ³•æˆ–æé—®ï¼**

</div>