---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG: A GraphRAG Alternative and Next-Gen RAG Framework"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.1|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["哈喽，大家好！","今天聊一个特别有意思、也特别实用的主题。","关于怎么让大语言模型","更聪明、更准确地理解和使用外部知识。/D/1000"],"en":["Hello everyone!","Today we're going to discuss a very interesting and practical topic.","It's about how to make Large Language Models","understand and use external knowledge more smartly and accurately./D/1000"]}}
---

# LightRAG: A GraphRAG Alternative

## Leveraging Knowledge Graphs and Vector Retrieval for Enhanced RAG

---
page: 2

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["现在的LLMs很厉害，","但有时候处理特定、最新的信息时，","还是会有点“一本正经地胡说八道”，对吧？/D/1000"],"en":["Current LLMs are powerful,","but sometimes when handling specific or the latest information,","they can still sound like they're confidently making things up, right?/D/1000"]},"click1":{"zh_CN":["那怎么解决这个问题呢？","就得靠RAG，也就是“检索增强生成”。","简单说，在LLM回答问题前，","先让它去外部资料里找找相关的“证据”，","再结合这些证据来生成回答。/D/1000"],"en":["So how do we solve this problem?","That's where RAG comes in, Retrieval-Augmented Generation.","Simply put, before the LLM answers a question,","it first searches external data for relevant 'evidence',","and then generates the answer based on that evidence./D/1000"]}}
---

# Why Enhance LLMs?

- LLMs are powerful but lack specific/latest knowledge.
- Can sometimes generate inaccurate or fabricated info (hallucination).

<div v-click="1">

## The Solution: Retrieval-Augmented Generation (RAG)

- Combine LLMs with external data.
- **Retrieve** relevant info first, then **Generate** response based on that info.

</div>


---
page: 3

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["今天我们要深入了解的，","是一个我觉得非常值得关注的RAG新框架——LightRAG。","LightRAG 是啥？","在我看来，LightRAG 可以说是RAG技术演进中的一个重要一步。/D/1000"],"en":["Today, the framework we're going to dive into,","is a new RAG framework that I find particularly noteworthy – LightRAG.","What is LightRAG?","In my view, LightRAG is a significant step in the evolution of RAG technology./D/1000"]},"click1":{"zh_CN":["它跟传统的RAG不太一样，","传统的RAG通常把文档切成小块，然后去搜索这些小块。","但这有个问题，就是容易丢失信息块之间的上下文关联。","一个概念、一件事可能跨了好几个段落，","你只看其中一个块，可能就理解偏了。/D/1000"],"en":["It's different from traditional RAG.","Traditional RAG usually breaks documents into small chunks and searches these chunks.","But the problem is, it's easy to lose the contextual connections between these information blocks.","A concept or event might span several paragraphs,","and if you only look at one chunk, you might misunderstand it./D/1000"]},"click2":{"zh_CN":["LightRAG聪明在哪儿呢？","它不只切块，还会构建知识图谱！","知识图谱就像一张巨大的思维导图，","把文档里的各种“实体”以及它们之间的“关系”都梳理出来，","形成实体-关系对。","这样，它就能捕捉到信息之间更复杂的联系了。/D/1000"],"en":["Where is LightRAG clever?","It doesn't just chunk; it also builds a knowledge graph!","A knowledge graph is like a huge mind map,","organizing various 'entities' in the document and the 'relationships' between them,","forming entity-relationship pairs.","This way, it can capture more complex connections between pieces of information./D/1000"]},"click3":{"zh_CN":["你可以想象一下，","传统RAG是给你一堆分散的积木块，","LightRAG是把这些积木块按照说明书拼好了一部分，","你知道哪个块跟哪个块是连着的。/D/1000"],"en":["You can imagine it this way:","Traditional RAG gives you a pile of scattered building blocks,","LightRAG assembles some of these blocks according to the instructions,","so you know which block is connected to which./D/1000"]}}
---

# What is LightRAG?

<div v-click="1">

- **Traditional RAG**: Chunks documents into isolated segments.
- Can sometimes lose context between chunks.

</div>

<div v-click="2">

- **LightRAG**: An advanced, cost-effective RAG framework.
- Uses **Knowledge Graphs** alongside **Embeddings**.
- Builds **entity-relationship pairs** to connect concepts, maintaining context.

</div>

<div v-click="3">

- *Analogy*: Traditional RAG gives scattered blocks, LightRAG provides partially assembled structures.

</div>


---
page: 4

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 和 GraphRAG 有什么不同？","说到知识图谱和RAG结合，你可能听说过微软的GraphRAG。","GraphRAG想法很酷，也是用图谱来增强检索。/D/1000"],"en":["What's the difference between LightRAG and GraphRAG?","Speaking of combining knowledge graphs and RAG, you might have heard of Microsoft's GraphRAG.","GraphRAG's idea is cool; it also uses graphs to enhance retrieval./D/1000"]},"click1":{"zh_CN":["但根据我的了解，GraphRAG有个不太“轻量”的地方，","它资源消耗比较大，","而且通常需要调用很多次甚至上百次昂贵的LLM API来构建图谱。","更麻烦的是，如果你更新了数据，","GraphRAG往往需要把整个图谱推倒重来，","这成本和时间就上去了。/D/1000"],"en":["But based on my understanding, GraphRAG has a not-so-'lightweight' aspect.","It's quite resource-intensive,","and often requires many, even hundreds of calls to expensive LLM APIs to build the graph.","What's more troublesome is, if you update the data,","GraphRAG often needs to completely rebuild the entire graph,","which drives up costs and time./D/1000"]}}
---

# LightRAG vs. GraphRAG

<div v-click="1">

- **GraphRAG (Microsoft)**: Similar idea (KG for RAG), but...
  - **Resource-intensive**: Requires many (hundreds) API calls.
  - **Expensive**: Often uses costly models (like GPT-4o).
  - **Full Rebuild**: Requires rebuilding the entire graph for data updates.

</div>


---
page: 5

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["这正是LightRAG的优势所在！","LightRAG的设计理念就是更轻量、更经济。/D/1000"],"en":["This is precisely where LightRAG's advantages lie!","LightRAG's design philosophy is to be more lightweight and cost-effective./D/1000"]},"click1":{"zh_CN":["它用的API调用次数更少，可以使用像GPT-4o-mini这样更轻量级的模型。/D/1000"],"en":["It uses fewer API calls and can utilize more lightweight models like GPT-4o-mini./D/1000"]},"click2":{"zh_CN":["更关键的是，它支持增量更新！","这意味着你有了新数据，不用重建整个图谱，","只需要把新信息加进去就行了。","这一点在信息变化快的领域简直太重要了，","你的知识库可以随时保持更新。/D/1000"],"en":["More importantly, it supports incremental updates!","This means when you have new data, you don't need to rebuild the entire graph,","you just add the new information.","This is incredibly important in fields where information changes quickly,","allowing your knowledge base to stay updated at all times./D/1000"]},"click3":{"zh_CN":["而双层检索（Dual-Level Retrieval）的设计，确保了.../D/1000"],"en":["And the design of Dual-Level Retrieval ensures that.../D/1000"]},"click4":{"zh_CN":["...结合图谱和向量搜索，LightRAG能更快、更准确地找到你需要的信息，","并且还有去重功能，","避免给你重复的内容，只呈现最重要的部分。/D/1000"],"en":["...by combining graph and vector search, LightRAG can find the information you need faster and more accurately,","and it also has deduplication functionality,","avoiding giving you redundant content and only presenting the most important parts./D/1000"]}}
---

# LightRAG's Advantages

<div v-click="1">

- **Cost-Effective**: Fewer API calls, uses lightweight models (e.g., GPT-4o-mini).

</div>

<div v-click="2">

- **Incremental Updates**: Adds new data without rebuilding the whole graph.

</div>

<div v-click="3">

- **Dual-Level Retrieval**: Combines local details with global context.

</div>

<div v-click="4">

- **Faster & More Accurate**: Improves response quality and speed.

</div>


---
page: 6

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 还有哪些亮点？","除了构建知识图谱和支持增量更新，/D/1000"],"en":["What other highlights does LightRAG have?","Besides building knowledge graphs and supporting incremental updates,/D/1000"]},"click1":{"zh_CN":["LightRAG还有一个我觉得特别棒的设计——双层检索（Dual-Level Retrieval）。","这是什么意思呢？","就像我们平时思考问题，","有时候需要抠细节，有时候需要看大局。/D/1000"],"en":["LightRAG has another design I think is particularly excellent – Dual-Level Retrieval.","What does this mean?","It's like how we usually think about problems,","sometimes we need to focus on details, and sometimes we need to see the bigger picture./D/1000"]},"click2":{"zh_CN":["LightRAG也能做到：","1. 低层检索 (Low Level Retrieval):","它会关注知识图谱里某个实体附近的节点和关系，","用来回答那些需要精确细节的问题。","比如某个法规的具体条款，或者某款产品的具体参数。/D/1000"],"en":["LightRAG can also do this:","1. Low-Level Retrieval:","It focuses on the nodes and relationships near a specific entity in the knowledge graph,","used to answer questions requiring precise details.","For example, the specific clauses of a regulation, or the exact parameters of a product./D/1000"]},"click3":{"zh_CN":["2. 高层检索 (High-Level Retrieval):","它会扫描整个图谱，","找出文档里的 overarching themes and connections。","这就像让你看到森林的全貌，","帮你理解整体的趋势或背景。/D/1000"],"en":["2. High-Level Retrieval:","It scans the entire graph,","identifying overarching themes and connections within the document.","This is like letting you see the whole forest,","helping you understand the overall trends or context./D/1000"]},"click4":{"zh_CN":["这种双层检索结合起来，","能确保生成的回答既有事实依据的细节，","又不失更广阔的上下文，","听起来是不是很全面？/D/1000"],"en":["Combining these two levels of retrieval,","ensures that the generated answers have both fact-based details,","and don't lose the broader context.","Doesn't that sound comprehensive?/D/1000"]}}
---

# LightRAG's Dual-Level Retrieval

<div v-click="1">

Combines **Local** and **Global** perspectives:

</div>

<div v-click="2">

1.  **Low-Level Retrieval**: Focuses on nearby nodes/relationships for **precise details**.
    - *Example*: Specific stats, regulations, facts.

</div>

<div v-click="3">

2.  **High-Level Retrieval**: Scans the entire graph for **overarching themes & connections**.
    - *Example*: Environmental trends, future outlooks, broader context.

</div>

<div v-click="4">

**Result**: Well-rounded answers with both facts and context.

</div>


---
page: 7

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 的工作流程是怎样的？","理解一个框架，最好是看看它是怎么运作的。/D/1000"],"en":["What is LightRAG's workflow like?","To understand a framework, it's best to see how it operates./D/1000"]},"click1":{"zh_CN":["LightRAG主要分两步：","1. 索引阶段 (Indexing Process): 构建知识图谱","2. 检索阶段 (Retrieval): 双层查询/D/1000"],"en":["LightRAG mainly consists of two steps:","1. Indexing Process: Building the Knowledge Graph","2. Retrieval: Dual-level querying/D/1000"]}}
---

# LightRAG Workflow

<div v-click="1">

## Two Main Stages:

1.  **Indexing**: Creating the Knowledge Graph
2.  **Retrieval**: Querying the Graph and Vector Database

</div>



---
page: 8

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["大家看一下这个流程图。","首先，你的文档会被切分成小块。/D/1000"],"en":["Let's look at this flowchart.","First, your documents will be divided into small chunks./D/1000"]},"click1":{"zh_CN":["然后，LLM会识别出每个块里的实体。/D/1000"],"en":["Then, the LLM will identify the entities within each chunk./D/1000"]},"click2":{"zh_CN":["接着，模型会分析这些实体之间的关系，","生成像“实体A - 关系 - 实体B”这样的键值对。/D/1000"],"en":["Next, the model will analyze the relationships between these entities,","generating pairs like 'Entity A - Relationship - Entity B'./D/1000"]},"click3":{"zh_CN":["这些实体和关系会被组织成一个图结构。","过程中会把重复的节点或关系去掉，优化图谱。/D/1000"],"en":["These entities and relationships will be organized into a graph structure.","During this process, duplicate nodes or relationships are removed, optimizing the graph./D/1000"]},"click4":{"zh_CN":["最后，这些实体描述和关系信息会被转换成向量，","存储到一个向量数据库里。","Nano Vector is the default database used by LightRAG./D/1000"],"en":["Finally, these entity descriptions and relationship information are converted into vectors,","and stored in a vector database.","Nano Vector is the default database used by LightRAG./D/1000"]}}
---

# LightRAG Workflow: Indexing Process

<div v-click="1">

1.  **Chunking**: Documents divided into small pieces.

</div>

<div v-click="2">

2.  **Entity Recognition**: LLM identifies entities in chunks.

</div>

<div v-click="3">

3.  **Relationship Extraction**: Model extracts relationships (entity-relationship pairs).

</div>

<div v-click="4">

4.  **Knowledge Graph Construction**: Pairs form a graph structure (duplicates removed).

</div>

<div v-click="5">

5.  **Embedding Storage**: Descriptions/relationships embedded and stored in a **vector database** (Default: Nano Vector).

</div>


---
page: 9

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["当你提出问题时，LightRAG就会利用上面建好的知识图谱和向量库进行搜索。/D/1000"],"en":["When you ask a question, LightRAG will use the knowledge graph and vector database built above to perform a search./D/1000"]},"click1":{"zh_CN":["它会同时或根据你的设置，","进行低层检索（聚焦细节）和高层检索（聚焦大局）。/D/1000"],"en":["It will perform, either simultaneously or based on your settings,","low-level retrieval (focusing on details) and high-level retrieval (focusing on the bigger picture)./D/1000"]},"click2":{"zh_CN":["找到的相关信息会被用来增强LLM的回答。/D/1000"],"en":["The relevant information found will be used to augment the LLM's response./D/1000"]}}
---

# LightRAG Workflow: Retrieval

<div v-click="1">

Uses **Dual-Level Retrieval**:

- **Low-Level**: Focuses on nearby nodes for **precise queries**.
- **High-Level**: Identifies overarching themes across the graph for **broader topics**.

</div>

<div v-click="2">

**Result**: Well-rounded answers with both facts and context.

</div>


---
page: 10

layout: two-cols
subtitles: {"default":{"zh_CN":["怎么用 LightRAG 呢？","棒的是，LightRAG的设置据说还挺方便的。/D/1000"],"en":["How do you use LightRAG?","The great thing is, LightRAG is said to be quite easy to set up./D/1000"]},"click1":{"zh_CN":["你可以从它的GitHub仓库克隆代码，或者用 pip 安装。/D/1000"],"en":["You can clone the code from its GitHub repository, or install it using pip./D/1000"]},"click2":{"zh_CN":["建议搭个虚拟环境。/D/1000"],"en":["It's recommended to set up a virtual environment./D/1000"]},"click3":{"zh_CN":["然后安装依赖。","接下来就可以用了！","无论是用 OpenAI 的模型还是免费的本地模型，LightRAG 都支持。/D/1000"],"en":["Then install the dependencies.","And then you can start using it!","LightRAG supports both OpenAI models and free local models./D/1000"]},"click4":{"zh_CN":["你可以把你的文档喂给它。/D/1000"],"en":["You can feed your documents into it./D/1000"]},"click5":{"zh_CN":["然后就可以用不同的模式来查询了。","关于这段代码。/D/1000"],"en":["Then you can query using different modes.","Regarding this code./D/1000"]},"click6":{"zh_CN":["这段代码展示了如何初始化 LightRAG 实例，","指定工作目录和使用的LLM模型（这里用了 GPT-4o-mini）。/D/1000"],"en":["This code demonstrates how to initialize the LightRAG instance,","specifying the working directory and the LLM model to use (GPT-4o-mini is used here)./D/1000"]}}
---

# Setting Up LightRAG (with OpenAI)

<div v-click="1">

1.  **Clone/Install**:
    ```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
# Or Install from PyPI
pip install lightrag-hku
    ```

</div>

<div v-click="2">

2.  **Virtual Environment**:
    ```bash
conda create -n lightrag python=3.12
conda activate lightrag
    ```

</div>

<div v-click="3">

3.  **Install Dependencies**:
    ```bash
pip install -e .
    ```

</div>

<div v-click="4">

4.  **Initialize LightRAG**:
    ```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)
    ```

</div>

<div v-click="5">

5. **Insert Data**:
```python
with open("./book.txt") as f:
    rag.insert(f.read())
```

</div>

<div v-click="6">

6. **Query Data**:
```python
# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))

# Perform local search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))

# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))

# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

</div>


::right::



---
page: 11

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["大家看一下这段代码中，`rag.query` 函数的参数。","特别是 `param=QueryParam(mode=\"...\")` 部分。","这里定义了不同的查询模式。/D/1000"],"en":["Look at the parameters of the `rag.query` function in this code.","Especially the `param=QueryParam(mode=\"...\")` part.","This is where different query modes are defined./D/1000"]},"click1":{"zh_CN":["`naive`：标准的、没用图谱的RAG。/D/1000"],"en":["`naive`: Standard RAG, without graph enhancement./D/1000"]},"click2":{"zh_CN":["`local`：基于实体邻近关系进行检索，偏重细节。/D/1000"],"en":["`local`: Retrieval based on entity neighborhood relationships, focusing on details./D/1000"]},"click3":{"zh_CN":["`global`：基于全局实体关系检索，偏重宏大主题。/D/1000"],"en":["`global`: Retrieval based on global entity relationships, focusing on broader themes./D/1000"]},"click4":{"zh_CN":["`hybrid`：结合 local 和 global 的优点。","你可以试试不同模式下，对同一个问题会得到什么样的回答，","这能帮你理解双层检索的神奇之处。/D/1000"],"en":["`hybrid`: Combines the benefits of both local and global modes.","You can try querying the same question in different modes,","which can help you understand the magic of dual-level retrieval./D/1000"]}}
---

# Query Modes

<div v-click="1">

- `naive`: Standard RAG (without graph enhancement).

</div>

<div v-click="2">

- `local`: Entity neighborhood-based retrieval (focus on details).

</div>

<div v-click="3">

- `global`: Broader, global entity relationships (focus on themes).

</div>

<div v-click="4">

- `hybrid`: Combines both local and global modes.

</div>


---
page: 12

layout: two-cols
subtitles: {"default":{"zh_CN":["Thats Alright, But i want to run with free and private models How to do that?","You can use ollama models for that as given in below code./D/1000"],"en":["That's alright, but I want to run with free and private models. How to do that?","You can use Ollama models for that as given in the below code./D/1000"]},"click1":{"zh_CN":["大家看一下这段代码。","这段代码展示了如何配置 LightRAG 来使用 Ollama 提供的本地模型。","需要指定 `llm_model_func` 为 `ollama_model_complete`，","以及通过 `embedding_func` 配置 Ollama 的 embedding 模型和相关参数。","插入数据和查询部分与使用 OpenAI 模型类似，","都是调用 `rag.insert` 和 `rag.query` 方法。/D/1000"],"en":["Let's look at this code.","This code shows how to configure LightRAG to use local models provided by Ollama.","You need to specify `llm_model_func` as `ollama_model_complete`,","and configure Ollama's embedding model and related parameters through `embedding_func`.","The data insertion and querying parts are similar to using OpenAI models,","both involve calling the `rag.insert` and `rag.query` methods./D/1000"]}}
---

# Setting Up LightRAG (with Local/Private Models - Ollama)

```python
import os

from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)


::right::


with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)

# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
)

# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)

# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```

---
page: 13

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 能用在哪儿？/D/1000"],"en":["Where can LightRAG be used?/D/1000"]},"click1":{"zh_CN":["因为 LightRAG 擅长处理复杂文档和分析实体关系，","它在不少行业都能派上大用场：/D/1000"],"en":["Because LightRAG excels at processing complex documents and analyzing entity relationships,","it can be very useful in many industries:/D/1000"]},"click2":{"zh_CN":["法律研究：分析法律条文、案例、判例之间的复杂关系。/D/1000"],"en":["Legal Research: Analyzing the complex relationships between laws, cases, and precedents./D/1000"]},"click3":{"zh_CN":["医疗健康：理解病人数据、症状、治疗方案之间的联系。","辅助诊断或研究。/D/1000"],"en":["Healthcare: Understanding the connections between patient data, symptoms, and treatment plans.","Assisting with diagnosis or research./D/1000"]},"click4":{"zh_CN":["农业：组织和检索农作物、土壤类型、天气模式等信息，","优化种植。/D/1000"],"en":["Agriculture: Organizing and retrieving information on crops, soil types, weather patterns, etc.,","to optimize cultivation./D/1000"]}}
---

# Key Use Cases for LightRAG

<div v-click="1">

LightRAG excels in analyzing complex documents and entity relationships:

</div>

<div v-click="2">

1.  **Legal Research**: Extract relationships between laws, cases, precedents.

</div>

<div v-click="3">

2.  **Healthcare**: Analyze patient data, symptoms, treatments for insights.

</div>

<div v-click="4">

3.  **Agriculture**: Organize info on crops, soil, weather for optimization.

</div>


---
page: 14

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["总结一下为什么选择 LightRAG？/D/1000"],"en":["To summarize, why choose LightRAG?/D/1000"]},"click1":{"zh_CN":["总的来说，LightRAG 把知识图谱集成分和向量检索结合起来，","代表了下一代 RAG 框架的方向。/D/1000"],"en":["Overall, LightRAG combines the knowledge graph component with vector retrieval,","representing the direction of next-generation RAG frameworks./D/1000"]},"click2":{"zh_CN":["它做到了轻量、经济，是 GraphRAG 等资源密集型方案的一个很好的替代。","相比起像 GraphRAG 那样资源密集型的方案，","LightRAG 在实用性和成本效益上确实更有优势。/D/1000"],"en":["It achieves lightweightness and cost-effectiveness, making it a great alternative to resource-intensive solutions like GraphRAG.","Compared to resource-intensive solutions like GraphRAG,","LightRAG indeed has advantages in terms of practicality and cost-effectiveness./D/1000"]},"click3":{"zh_CN":["而且，它支持增量更新，这一点非常重要。/D/1000"],"en":["Furthermore, it supports incremental updates, which is very important./D/1000"]},"click4":{"zh_CN":["它的双层检索功能，能提供更全面、更理解上下文的回答。/D/1000"],"en":["Its dual-level retrieval feature can provide more comprehensive and context-aware answers./D/1000"]},"click5":{"zh_CN":["所以，如果你需要处理大型数据集，","或者希望获得更智能、更理解上下文的回答，","LightRAG 提供了一个强大的、而且是开源的选择。/D/1000"],"en":["Therefore, if you need to process large datasets,","or hope to get smarter, more context-aware answers,","LightRAG offers a powerful and open-source option./D/1000"]}}
---

# Conclusion: Why Choose LightRAG?

<div v-click="1">

- Next-gen RAG combining **Knowledge Graphs** and **Vector Retrieval**.

</div>

<div v-click="2">

- **Lightweight** & **Cost-effective** alternative to GraphRAG.

</div>

<div v-click="3">

- Supports **Incremental Updates**.

</div>

<div v-click="4">

- Features **Dual-Level Retrieval** for comprehensive answers.

</div>

<div v-click="5">

Ideal for large datasets and intelligent, context-aware responses.

</div>


---
page: 15

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["好啦，关于 LightRAG，今天就先聊到这儿。","希望这些信息对你有启发！/D/1000"],"en":["Alright, that's all for today about LightRAG.","Hope this information was insightful for you!/D/1000"]},"click1":{"zh_CN":["最后一个问题留给你思考：","在你的工作或学习中，有没有哪些场景是你觉得特别需要理解复杂文档中实体和它们之间关系的呢？","LightRAG 这种基于知识图谱的 RAG 方法，","在你看来有哪些潜在的应用可能性？/D/1000"],"en":["Here's a final question for you to ponder:","In your work or studies, are there any scenarios where you feel a particular need to understand the entities in complex documents and the relationships between them?","What potential application possibilities do you see for LightRAG's knowledge graph-based RAG approach?","What are your thoughts on LightRAG? Potential use cases in your field?/D/1000"]}}
---

# Thank You & Q&A

<div v-click="1">

- What are your thoughts on LightRAG?
- Potential use cases in your field?

</div>
