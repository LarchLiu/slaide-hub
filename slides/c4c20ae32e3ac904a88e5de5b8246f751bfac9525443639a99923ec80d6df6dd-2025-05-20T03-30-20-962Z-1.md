---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG：GraphRAG 的一个替代方案"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.1|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["嘿！朋友们！","今天咱们来聊一个特别有意思、","而且我觉得对咱们高效获取信息特别有帮助的新玩意儿——","它叫 LightRAG。"],"en":["Hey everyone!","Today, let's talk about something particularly interesting,","and I think it's a new tool that's really helpful for efficiently getting information –","It's called LightRAG."]}}
---

# LightRAG：GraphRAG 的一个替代方案

## 下一代 RAG 框架

---
page: 2

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["嗯，你可能听说过 RAG，","就是那种让大语言模型能查外部资料回答问题的技术。"],"en":["So, you might have heard of RAG,","It's the technique that allows large language models to query external data to answer questions."]}}
---

## 什么是 RAG？

- **R**etrieval-
- **A**ugmented
- **G**eneration

结合 LLM 和外部数据回答问题

---
page: 3

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["我说啊，传统 RAG 系统挺棒的，","它能把你的文档切成小块，","然后让模型去这些小块里找答案。","但这有个问题，你想想，","书里或者文章里的意思，","很多时候不是孤立的一句话能说清楚的，","它得联系上下文，","联系不同段落之间的关系，对吧？","传统 RAG 呢，恰恰就容易忽略这些“关系”，","只看到分散的信息点。"],"en":["Traditional RAG systems are great,","They can split your documents into small chunks,","and then the model searches within these chunks for answers.","But there's a problem. Think about it,","The meaning in books or articles,","Often isn't clear from a single isolated sentence,","It needs to connect to the context,","And relate different paragraphs, right?","Traditional RAG, however, tends to ignore these \"relationships\",","Only seeing scattered information points."]}}
---

## 传统 RAG 的局限性

- 将文档切成孤立的块
- 容易忽略信息块之间的**上下文关系**
- 难以准确回答涉及跨块联系的复杂问题

---
page: 4

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 解决的正是这个问题！","它不只是简单地切块，","它会更进一步，"],"en":["LightRAG solves exactly this problem!","It doesn't just simply chunk,","It goes a step further,"]},"click1":{"zh_CN":["去建立数据里的“实体-关系对”。","什么意思呢？","就是找出文档里提到的关键概念，","然后搞清楚这些实体之间有什么联系。","比如，“A 影响了 B”，“C 属于 D”这样。"],"en":["To build \"Entity-Relationship Pairs\" from the data.","What does that mean?","It's about identifying the key concepts mentioned in the document,","And then figuring out what connections exist between these entities.","For example, \"A affects B\", \"C belongs to D\", and so on."]},"click2":{"zh_CN":["听到这儿，你可能觉得有点像“知识图谱”，","没错！","LightRAG 就是把这些关系织成了一张巨大的网，","一个知识图谱。","有了这张“关系网”，","模型就不仅仅是看一个个零散的信息点，","它能看到信息点之间的联系，","理解更深层的含义和上下文。"],"en":["Hearing this, you might think it sounds a bit like a \"Knowledge Graph\",","Exactly!","LightRAG weaves these relationships into a giant network,","A knowledge graph.","With this \"relationship network\",","The model doesn't just see scattered information points,","It can see the connections between them,","Understanding deeper meaning and context."]}}
---

## LightRAG 的核心创新

- 不仅切块，更进一步构建：

<div v-click="1">

  - **实体-关系对** (Entity-Relationship Pairs)
  - 连接文本中的概念

</div>

<div v-click="2">

- 将关系对织成：
  - **知识图谱** (Knowledge Graph)
  - 理解深层含义和上下文

</div>

---
page: 5

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你可能还听说过微软的 GraphRAG，","它也是基于知识图谱的。","但我在设计 LightRAG 的时候，","发现 GraphRAG 有些地方可以改进。","GraphRAG 用起来比较“重”，","需要调用很多次 API，","而且常常要用像 GPT-4o 这种比较贵的模型。","更关键的是，如果你更新了数据，","GraphRAG 可能得把整个图谱从头到尾重建一遍，","这就又费时又费钱。"],"en":["You might also have heard of Microsoft's GraphRAG,","It's also based on knowledge graphs.","But while designing LightRAG,","I found some areas where GraphRAG could be improved.","GraphRAG is relatively \"heavy\" to use,","Requiring many API calls,","And often needing expensive models like GPT-4o.","More importantly, if you update the data,","GraphRAG might have to rebuild the entire graph from scratch,","Which is time-consuming and costly."]}}
---

## 对比 GraphRAG

- **GraphRAG (Microsoft)**
  - 基于知识图谱
  - **资源密集**
  - 需要**大量 API 调用**
  - 常用昂贵模型 (e.g., GPT-4o)
  - **更新数据需重建整个图谱**

---
page: 6

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 呢，就轻巧多了：","首先，它需要的 API 调用次数少，"],"en":["LightRAG, however, is much lighter:","First, it requires fewer API calls,"]},"click1":{"zh_CN":["可以用像 GPT-4o-mini 这样更轻量级的模型，","所以成本更低。"],"en":["You can use lighter models like GPT-4o-mini,","So the cost is lower."]},"click2":{"zh_CN":["其次，也是一个超大的亮点，","它支持“增量更新”！","也就是说，你加了新数据，","它不用把整个图谱推倒重建，","它能很快地把新信息和现有图谱连接起来，","就像给图谱打补丁一样。"],"en":["Secondly, and a huge highlight,","It supports \"incremental updates\"!","Meaning, if you add new data,","It doesn't need to tear down and rebuild the whole graph,","It can quickly connect the new information to the existing graph,","Like patching the graph."]},"click3":{"zh_CN":["再来，它还有一个独特的功能叫“双层检索”。"],"en":["Furthermore, it has a unique feature called \"Dual-Level Retrieval\"."]}}
---

## LightRAG 的优势

- **轻巧高效**

<div v-click="1">

  - **更少 API 调用**
  - 可用轻量模型 (e.g., GPT-4o-mini)
  - **成本更低**

</div>

<div v-click="2">

- **支持增量更新**
  - 无需重建，快速整合新数据

</div>

<div v-click="3">

- **双层检索** (Local & Global)
  - 提升回答质量

</div>

---
page: 7

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["这个特别牛，尤其是在信息更新超快的地方，","比如新闻、股票、或者技术文档这些领域，","你的信息才能随时保持最新。"],"en":["This is especially powerful in fields where information updates very quickly,","Like news, stocks, or technical documentation,","Your information can stay up-to-date at all times."]}}
---

## 增量更新系统

- 关键特性，适应快速变化的信息领域
- 无需重建整个知识库
- 快速添加新数据
- 确保答案随时保持最新

---
page: 8

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["那它是怎么做到的呢？"],"en":["So how does it do that?"]}}
---

## 更快、更智能的检索

- 结合：
  - **知识图谱** (关系)
  - **向量搜索** (相似性)
- 有效组织相关想法
- **去重功能** (Deduplication)
- 只呈现最重要信息

---
page: 9

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["测试表明，LightRAG 在准确性和速度上都比旧的 RAG 模型有显著提升。","它也能优雅地处理新信息，这意味着你得到的答案总是最新的且具有上下文感知能力。","这使得它在需要快速、相关响应的应用中成为游戏规则的改变者，比如聊天机器人、个人助理和动态搜索工具。"],"en":["Tests show that LightRAG significantly improves both accuracy and speed compared to older RAG models.","It also handles new information gracefully, meaning you get up-to-date and context-aware answers every time.","This makes it a game-changer for applications where quick, relevant responses are key — like chatbots, personal assistants, and dynamic search tools."]}}
---

## LightRAG 价值与评估

- 显著提升：
  - **准确性**
  - **速度**
- 优雅处理新信息
- 适用于需要快速、相关回答的应用

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)

*评估截图*

---
page: 10

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 的工作流程分为两个主要阶段——索引（Indexing）和检索（Retrieval）。"],"en":["LightRAG’s workflow is divided into two main stages — Indexing and Retrieval."]}}
---

## LightRAG 工作流程概览

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)

*来自 LightRAG 项目的流程图*

---
page: 11

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["整个流程分成两大步：","第一步：建知识库（索引 Indexing）","就像我刚才说的，它先把你的文档“切块”（Chunking）。","然后让模型读这些块，找出里面的“实体”。","接着，它会分析这些实体，","提取它们之间的“关系”，","生成那种“谁跟谁有什么关系”的关键信息对。"],"en":["The whole process is divided into two main steps:","Step one: Building the knowledge base (Indexing)","As I just mentioned, it first \"chunks\" your document (Chunking).","Then it has the model read these chunks and identify the \"entities\" within them.","Next, it analyzes these entities,","Extracting the \"relationships\" between them,","Generating key information pairs like \"who has what relationship with whom\"."]}}
---

## 第一阶段：建知识库 (Indexing)

1.  **切块 (Chunking):** 将文档分成小块。
2.  **实体识别 (Entity Recognition):** LLM 识别块内实体。
3.  **关系提取 (Relationship Extraction):** 提取实体间关系，生成“实体-关系对”。

---
page: 12

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["有了这些关系对，它就开始“构建知识图谱”，","把它们连接起来。","在这个过程中，它会把重复的节点或关系去掉，","让图谱更精炼。","最后，它把这些关系和描述变成数字形式，","存到一个专门的“向量数据库”里，"],"en":["With these relationship pairs, it starts \"Building the Knowledge Graph\",","Connecting them together.","In this process, it removes duplicate nodes or relationships,","Making the graph more refined.","Finally, it transforms these relationships and descriptions into numerical forms,","Storing them in a dedicated \"Vector Database\","]}}
---

## 第一阶段：建知识库 (Indexing)

4.  **知识图谱构建 (Knowledge Graph Construction):** 组合关系对，构建图谱，去除冗余。
5.  **向量存储 (Embedding Storage):** 将描述和关系嵌入为向量，存入向量数据库。

---
page: 13

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["它默认用的数据库叫 Nano Vector。"],"en":["The database it uses by default is called Nano Vector."]}}
---

## 默认向量数据库

Nano Vector

*LightRAG 默认使用的数据库*

---
page: 14

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["第二步：查问题（检索 Retrieval）","等你来问问题了，","LightRAG 的“双层检索”就开始发力了。"],"en":["Step two: Querying (Retrieval)","When you come with a question,","LightRAG's \"Dual-Level Retrieval\" starts working."]}}
---

## 第二阶段：查问题 (Retrieval)

- **双层检索 (Dual-Level Retrieval)**
  - 结合 **本地 (Local)** 和 **全局 (Global)** 查询
  - 低层检索 (Low Level Retrieval)
  - 高层检索 (High-Level Retrieval)

---
page: 15

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["低层检索 (Low Level Retrieval):","这就像你拿个放大镜，","它会聚焦在跟你问题最直接相关的那个实体，","以及它周围很近的一些关系和信息。","这个模式特别适合回答那些需要精确细节的问题，","比如某个具体的数据、某个特定的规定等等。"],"en":["Low Level Retrieval:","It's like holding a magnifying glass,","It focuses on the entity most directly related to your question,","And some very close relationships and information around it.","This mode is particularly suitable for answering questions that require precise details,","Such as a specific piece of data, a particular regulation, and so on."]},"click1":{"zh_CN":["高层检索 (High-Level Retrieval):","这个模式呢，就像你坐飞机从高空看地面，","它会关注整个知识图谱里那些更宏观、更大范围的主题和联系。","它能帮你抓住主要脉络，","理解事情的背景和整体趋势。"],"en":["High-Level Retrieval:","This mode, well, it's like looking at the ground from high up in an airplane,","It focuses on the more macro, broader themes and connections throughout the entire knowledge graph.","It helps you grasp the main threads,","Understanding the background and overall trends of things."]}}
---

## 双层检索模式

- **低层检索 (Local):**
  - 聚焦附近节点 (实体周边)
  - 回答**精确查询** (具体事实、规定)

<div v-click="1">

- **高层检索 (Global):**
  - 识别整个图谱的**宏观主题与联系**
  - 理解背景和趋势

</div>

---
page: 16

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["混合检索 (Hybrid):","当然，你也可以选择混合模式，","让它既看细节又看全局，","这样给出的答案通常更全面、更平衡。"],"en":["Hybrid Retrieval:","Of course, you can also choose the hybrid mode,","Allowing it to look at both details and the big picture,","This usually provides more comprehensive and balanced answers."]},"click1":{"zh_CN":["还有一个朴素检索 (Naive) 模式，","就像传统 RAG 那样。","所以你看，通过结合这两种检索方式，","LightRAG 能给你那种既有具体事实支撑，","又能看到整个背景和关系的答案，","非常强大！"],"en":["There's also a Naive Retrieval mode,","Just like traditional RAG.","So you see, by combining these two retrieval methods,","LightRAG can give you answers that are supported by specific facts,","And also show the entire background and relationships,","Very powerful!"]}}
---

## 双层检索模式 (续)

- **混合检索 (Hybrid):**
  - 结合本地和全局模式
  - 提供更全面、均衡的答案

<div v-click="1">

- **朴素检索 (Naive):**
  - 标准 RAG 模式

</div>

---
page: 17

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你可能要问了，这听起来挺高级的。","用起来麻烦吗？","别担心，我就是奔着“易用”去设计的。","它是开源的，你在 GitHub 上把它克隆下来，","或者用 pip 命令就能轻松安装。","而且特别灵活，"],"en":["You might be wondering, this sounds quite advanced.","Is it troublesome to use?","Don't worry, I designed it with \"ease of use\" in mind.","It's open source, you can clone it from GitHub,","Or install it easily using the pip command.","And it's particularly flexible,"]}}
---

## 如何设置 LightRAG

- **易于安装与使用**
- **开源项目** (GitHub)
- 可通过 `git clone` 或 `pip install` 安装
- **高度灵活**：支持多种 LLM 模型

---
page: 18

layout: two-cols
subtitles: {"default":{"zh_CN":["你可以用 OpenAI 的模型，","大家可以看一下幻灯片上的代码示例。"],"en":["You can use OpenAI's models,","You can take a look at the code example on the slide."]}}
---

## 设置 LightRAG: 使用 OpenAI 模型

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

#########
# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()
# import nest_asyncio 
# nest_asyncio.apply() 
#########

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(


::right::

    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)

with open("./book.txt") as f:
    rag.insert(f.read())

# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))

# Perform local search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))

# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))

# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

---
page: 19

layout: two-cols
subtitles: {"default":{"zh_CN":["也可以用完全免费、可以在你本地跑的模型，","比如 ollama 里的模型，","大家可以看一下这个代码示例，展示了如何用 Ollama 模型进行设置。","非常方便上手。","那这东西到底能用在哪儿呢？","我觉得啊，在那些需要处理大量复杂文档、","而且文档里各种概念关系盘根错节的领域，","LightRAG 特别能打！"],"en":["You can also use completely free models that can run locally,","Like models in Ollama,","You can look at this code example, which shows how to set it up with an Ollama model.","It's very easy to get started.","So, where can this thing actually be used?","I think, in areas that need to process a large amount of complex documents,","And where the relationships between various concepts in the documents are intricate,","LightRAG is particularly effective!"]}}
---

## 设置 LightRAG: 使用免费/私有模型 (Ollama)

```python
import os

from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)


::right::


with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)

# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
)

# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)

# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```

---
page: 20

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["比如：","法律研究：","想想律师要处理的那些法条、案例、判例之间的引用和联系，","用 LightRAG 就能更快地理清关系。"],"en":["For example:","Legal Research:","Think about the citations and connections between statutes, cases, and precedents that lawyers have to handle,","Using LightRAG can help clarify these relationships faster."]},"click1":{"zh_CN":["医疗健康：","分析病人的数据、症状、检查结果、治疗方案之间的联系，","帮助医生或研究人员发现隐藏的医学见解。"],"en":["Healthcare:","Analyzing the connections between patient data, symptoms, test results, and treatment plans,","Helping doctors or researchers uncover hidden medical insights."]}}
---

## 关键应用场景 (1/2)

- **法律研究:**
  - 提取法条、案例、判例间的关系
  - 理清复杂法律条文

<div v-click="1">

- **医疗健康:**
  - 分析病人数据、症状、治疗方案联系
  - 发现隐藏的医学见解

</div>

---
page: 21

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["农业：","组织和查询作物种类、土壤类型、天气数据、施肥灌溉记录这些信息，","帮农民或农学家做出更科学的决策。"],"en":["Agriculture:","Organizing and querying information like crop types, soil types, weather data, and fertilization/irrigation records,","Helping farmers or agronomists make more scientific decisions."]},"click1":{"zh_CN":["总的来说，"],"en":["In summary,"]}}
---

## 关键应用场景 (2/2)

- **农业:**
  - 组织作物、土壤、天气、记录等信息
  - 辅助科学决策

<div v-click="1">

- **总结:**
  - 适用于处理**复杂文档**
  - 需要**实体级分析**的领域

</div>

---
page: 22

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["我认为 LightRAG 确实是 RAG 技术往前迈了一大步，","它把知识图谱和向量检索结合起来，","做到了轻量级、高效率、低成本，","而且能很优雅地处理信息的更新和复杂的上下文关系。","无论是你需要处理海量数据，","还是想要更智能、更贴近上下文的回答，","LightRAG 都提供了一个非常强大的开源选择。","强烈推荐你试试看，","体验一下“下一代 RAG”！"],"en":["I believe LightRAG is indeed a significant step forward for RAG technology,","It combines knowledge graphs and vector retrieval,","Achieving lightweight, high efficiency, and low cost,","And it can gracefully handle information updates and complex contextual relationships.","Whether you need to process massive data,","Or want more intelligent, context-aware answers,","LightRAG offers a very powerful open-source option.","I highly recommend you give it a try,","And experience the \"next-generation RAG\"!"]}}
---

## 结论：为何选择 LightRAG？

- **下一代 RAG**
- 结合：**知识图谱** + **向量检索**
- **轻量、高效、成本低**
- 支持**增量更新**
- **双层检索** (细节+全局上下文)

---

---
page: 23

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["好啦，今天关于 LightRAG 就聊到这儿。","听了这么多，你有没有想过，","在你的日常学习或工作中，","有没有哪个场景特别需要这种既能看到细节又能把握全局、","而且信息能随时更新的能力呢？","谢谢大家的聆听！"],"en":["Alright, that's all for today about LightRAG.","After listening to all this, have you thought,","In your daily study or work,","Is there any scenario where this ability to see both details and the big picture,","And have information updated at any time, is particularly needed?","Thank you all for listening!"]}}
---

## 谢谢！

Q&A