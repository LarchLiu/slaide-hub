---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG: A GraphRAG Alternative"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.2|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["哈喽！各位对高效信息获取和处理感兴趣的朋友们，欢迎回来！","今天，我要跟你聊一个我觉得超有意思、而且潜力巨大的新工具，","叫做 LightRAG。","它嘛，可以看作是目前大家都在说的 RAG 技术的一个升级版，","特别是对比像微软家的 GraphRAG，它有自己独特的优势。"],"en":["Hello everyone, welcome back to those interested in efficient information retrieval and processing!","Today, I want to talk to you about a tool I find super interesting and potentially powerful,","called LightRAG.","Well, you can think of it as an upgraded version of the RAG technology that everyone is talking about,","especially compared to tools like Microsoft's GraphRAG, it has its unique advantages."]}}
---

# LightRAG: A GraphRAG Alternative

## Retrieval-Augmented Generation Framework

Presented by Samar Singh

*   Advanced, cost-effective RAG
*   Integrates Knowledge Graphs & Vector Retrieval
*   Enhances document interaction
*   Compares to traditional RAG like GraphRAG

---
page: 2

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["简单来说，它能帮你更聪明、更高效地从大量文档里找到你需要的信息，","并且理解信息之间的关系。","那 LightRAG 到底是什么呢？","嗯，你可以想象，传统的 RAG 系统处理文档时，","就像是把一大本书切成很多小片段，","然后当你提问时，它就去这些小片段里大海捞针找最相关的。","这种方式挺好，但有个问题：","它可能会忽略掉片段之间的联系和上下文。","比如，一段讲人物A，一段讲人物B，","但人物A和B是什么关系，它可能就没抓到。"],"en":["Simply put, it helps you find the information you need from a large number of documents more intelligently and efficiently,","and understand the relationships between the information.","So, what exactly is LightRAG?","Well, you can imagine that when traditional RAG systems process documents,","it's like cutting a big book into many small fragments,","and when you ask a question, it searches for the most relevant fragments among these small pieces.","This method is good, but there's a problem:","It might ignore the connections and context between fragments.","For example, one paragraph talks about person A, and another talks about person B,","but it might not capture the relationship between person A and B."]}}
---

# What is LightRAG?

## Streamlined RAG with Context Awareness

*   **Retrieval-Augmented Generation (RAG)**: Combines LLMs with external data.
*   **Traditional RAG**: Chunks documents into isolated segments.
    *   Misses **contextual relationships** between segments.
    *   Difficult to answer complex questions spanning multiple chunks.

LightRAG enhances RAG by using **knowledge graphs** alongside **embeddings**.

---
page: 3

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 呢，它厉害的地方在于，它不光是切片段，","它还会建立一个知识图谱。","就是说，它会识别出文档里的关键概念，","然后找出这些概念之间的关系，把它们连接起来，","形成一张“关系网”。","这样一来，当我问一个问题时，","它不仅能找到包含关键词的片段，","还能理解这些关键词背后的实体及其相互关系。"],"en":["LightRAG, its strength lies in the fact that it doesn't just cut fragments,","it also builds a knowledge graph.","That is to say, it will identify the key concepts in the document,","and then find the relationships between these concepts, connect them,","forming a 'relationship network'.","This way, when I ask a question,","it can not only find fragments containing keywords,","but also understand the entities behind these keywords and their relationships."]}}
---

# LightRAG's Core: Knowledge Graphs

## Building Entity-Relationship Pairs

LightRAG solves the context issue by generating **knowledge graphs**.

*   Identifies **entities** (concepts, people, places).
*   Extracts **relationships** between entities.
*   Builds **entity-relationship pairs** connecting concepts.
*   Maps relationships into a **graph structure**.

This

---
page: 4

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["哎，说到知识图谱，你可能听说过微软的 GraphRAG，","想法是有点像。","但我发现 LightRAG 有几个特别突出的地方："],"en":["Hey, speaking of knowledge graphs, you might have heard of Microsoft's GraphRAG,","the idea is somewhat similar.","But I've found that LightRAG has a few particularly outstanding aspects:"]},"click1":{"zh_CN":["首先是速度更快，成本更低。","GraphRAG 有时候需要调用很多次的 API，比如像 GPT-4o 这样比较贵的模型。","而 LightRAG 呢，它使用的 API 调用次数相对少，","而且可以用像 GPT-4o-mini 这种更轻量级的模型，"],"en":["First is speed, it's faster and the cost is lower.","GraphRAG sometimes requires many API calls, for example, with expensive models like GPT-4o.","Whereas LightRAG, it uses relatively fewer API calls,","and can use lighter models like GPT-4o-mini,"]},"click2":{"zh_CN":["甚至还可以跟 Ollama 结合，让你用免费或者本地部署的模型。","这在处理大量数据时，能省下不少钱和时间，是不是很香？"],"en":["and can even be combined with Ollama, allowing you to use free or locally deployed models.","This can save a lot of money and time when dealing with large amounts of data, isn't that great?"]},"click3":{"zh_CN":["再来，我觉得它最赞的一点是支持增量更新。","你知道吗，GraphRAG 在数据更新时，","可能需要把整个知识图谱都重新构建一遍，这又慢又贵。","但 LightRAG 不用，它能像搭积木一样，","只把你新加的数据快速添加到现有的图谱里，","不用全部推倒重来。","这对于信息变化很快的领域，简直是救星，","能确保你的信息总是最新的。"],"en":["Furthermore, I think its most admirable point is support for incremental updates.","Did you know that when data is updated in GraphRAG,","it might need to rebuild the entire knowledge graph, which is slow and expensive.","But LightRAG doesn't, it can add new data quickly to the existing graph, like building with blocks,","without having to tear everything down and rebuild.","This is a lifesaver for fields where information changes quickly,","and can ensure your information is always up-to-date."]}}
---

# LightRAG vs. GraphRAG

## Key Advantages

LightRAG offers significant improvements over resource-intensive methods like Microsoft's GraphRAG:

| Feature             | GraphRAG                      | LightRAG                            |
| :------------------ | :---------------------------- | :---------------------------------- |

<div v-click="1">

| **Cost**            | Resource-intensive            | More affordable                     |
| **API Calls**       | Hundreds, often expensive LLMs| Fewer, supports lightweight models  |

</div>

<div v-click="2">

| **Model Flexibility**| Primarily high-cost LLMs      | Supports GPT-4o-mini, Ollama (Free/Private) |

</div>

<div v-click="3">

| **Updates**         | Rebuilds entire graph         | Allows **incremental updates**      |

</div>

---
page: 5

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["再来，我觉得它最赞的一点是支持增量更新。","你知道吗，GraphRAG 在数据更新时，","可能需要把整个知识图谱都重新构建一遍，这又慢又贵。","但 LightRAG 不用，它能像搭积木一样，"],"en":["Furthermore, I think its most admirable point is support for incremental updates.","Did you know that when data is updated in GraphRAG,","it might need to rebuild the entire knowledge graph, which is slow and expensive.","But LightRAG doesn't, it can add new data quickly to the existing graph, like building with blocks,"]},"click1":{"zh_CN":["只把你新加的数据快速添加到现有的图谱里，","不用全部推倒重来。","这对于信息变化很快的领域，简直是救星，","能确保你的信息总是最新的。"],"en":["only quickly add the new data you've added to the existing graph,","without having to tear everything down and rebuild.","This is a lifesaver for fields where information changes quickly,","and can ensure your information is always up-to-date."]}}
---

# LightRAG's Incremental Update System

## Keeping Information Fresh

*   Crucial in fast-changing fields (technology, news).

<div v-click="1">

*   GraphRAG requires rebuilding the entire graph on data updates.
*   LightRAG **doesn't rebuild** the whole knowledge base.
*   Quickly **adds fresh data** to the existing graph.
*   Ensures answers stay **relevant** and **up-to-date**.

</div>

---
page: 6

layout: two-cols
subtitles: {"default":{"zh_CN":["另外，LightRAG 的检索方式也很聪明，","它有个双层检索系统。"],"en":["In addition, LightRAG's retrieval method is also very smart,","it has a dual-level retrieval system."]},"click1":{"zh_CN":["一层是低层检索，或者叫本地检索，","它会聚焦到你问题相关的实体附近，","去挖那些紧密关联的细节信息，比如具体的数字、规定等等。"],"en":["One layer is low-level retrieval, or local retrieval,","it will focus on the area around the entity related to your question,","to dig out closely related detailed information, such as specific numbers, regulations, etc."]},"click2":{"zh_CN":["另一层是高层检索，或者叫全局检索，","它会放眼整个知识图谱，去抓取那些贯穿全局的主题、概念，","以及它们之间更宏观的联系，","就像是看懂了整个故事的“大图景”。"],"en":["The other layer is high-level retrieval, or global retrieval,","it will look at the entire knowledge graph,","and capture the overarching themes, concepts,","and their more macroscopic connections across the whole text,","It's like understanding the 'big picture' of the entire story."]},"click3":{"zh_CN":["它甚至还有一个混合模式，能把这两种检索方式结合起来用。","这样双管齐下，你得到的答案就不光是零散的事实，","而是既有具体的细节，又有完整的上下文和背景，","信息更全面、更深入。","而且，它还有一个去重功能，","能帮你去掉重复的信息，只呈现最有价值的内容。"],"en":["It even has a hybrid mode that can combine these two retrieval methods.","With this dual approach, the answers you get are not just scattered facts,","but include both specific details and complete context and background,","making the information more comprehensive and in-depth.","Moreover, it has a deduplication feature,","which can help you remove repetitive information and only present the most valuable content."]}}
---

# Dual-Level Retrieval System

## Covering Details and the Big Picture

LightRAG uses a combination of **local** and **global** queries:

<div v-click="1">

1.  **Low-Level (Local) Retrieval**:
    *   Focuses on nearby nodes/relationships (e.g., around a single entity).
    *   Answers **precise queries**.
    *   Pulls out detailed facts (stats, regulations).

</div>

<div v-click="2">

2.  **High-Level (Global) Retrieval**:
    *   Identifies overarching themes and connections across the entire graph.
    *   Focuses on **broader topics** (trends, future outlook).

</div>

<div v-click="3">

*   Also supports **Hybrid mode** combining both.
*   **Deduplication feature** removes repetitive information.

</div>

::right::



---
page: 7

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 的工作流程主要分为两个阶段：构建索引和进行检索。"],"en":["LightRAG's workflow is mainly divided into two stages: building the index and performing retrieval."]},"click1":{"zh_CN":["大家看一下这个流程图就一目了然了。"],"en":["Take a look at this workflow diagram, it's clear at a glance."]}}
---

# LightRAG Workflow Overview

## Two Main Stages

LightRAG's process is divided into:

1.  **Indexing**: Creating the Knowledge Graphs.
2.  **Retrieval**: Using the graphs for dual-level search.

<div v-click="1">

![LightRAG Workflow](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)

*   *As shown in the workflow diagram...*

</div>

---
page: 8

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["首先来看构建索引的过程：","文档会被切分成小块。"],"en":["First, let's look at the indexing process:","Documents are divided into smaller chunks."]},"click1":{"zh_CN":["语言模型会识别出这些小块里的关键实体，比如人、地名、概念等。","接着，模型会提取这些实体之间的关系，形成一个个实体-关系对。","这些关系对会被用来构建知识图谱。","图谱会进行优化，去除重复的节点或关系。","最后，图谱里的描述和关系会被转换成向量，存储到向量数据库里。","LightRAG 默认使用 Nano Vector 数据库。"],"en":["The language model identifies key entities within these chunks, such as people, places, concepts, etc.","Next, the model extracts the relationships between these entities, forming entity-relationship pairs.","These relationship pairs are used to construct the knowledge graph.","The graph is optimized to remove duplicate nodes or relationships.","Finally, the descriptions and relationships in the graph are converted into vectors and stored in a vector database.","LightRAG defaults to using the Nano Vector database."]}}
---

# Workflow Stage 1: Indexing Process

## Creating Knowledge Graphs from Documents

Here's how your data is indexed in LightRAG:

<div v-click="1">

1.  **Chunking**: Documents divided into smaller chunks.
2.  **Entity Recognition**: LLM identifies entities within chunks.
3.  **Relationship Extraction**: LLM determines relationships, generating **entity-relationship key-value pairs**.
4.  **Knowledge Graph Construction**: Pairs combined into a **graph structure**, optimized by removing duplicates.
5.  **Embedding Storage**: Descriptions and relationships embedded into vectors, stored in a **vector database** (e.g., Nano Vector).

*   *Nano Vector is the default database.*

</div>

---
page: 9

layout: two-cols
subtitles: {"default":{"zh_CN":["接下来是检索阶段，也就是双层检索的工作方式："],"en":["Next is the retrieval stage, which is how dual-level retrieval works:"]},"click1":{"zh_CN":["低层检索会聚焦到具体的实体和它周围的节点上，","用来回答需要精确细节的问题。","比如，你要查电动车的具体数据或者某个法律条文，就会用到它。"],"en":["Low-level retrieval focuses on specific entities and their neighboring nodes,","used to answer questions requiring precise details.","For example, if you want to check specific data on electric cars or a certain legal article, you would use it."]},"click2":{"zh_CN":["高层检索呢，会扫描整个图谱，","找出不同概念之间更宏观的联系和贯穿全文的主题。","比如，你想了解环保的大趋势或者未来交通的发展方向，就会用到它。"],"en":["High-level retrieval, on the other hand, scans the entire graph,","identifying more macroscopic connections between different concepts and overarching themes throughout the text.","For example, if you want to understand the big trends in environmental protection or the future direction of transportation, you would use it."]},"click3":{"zh_CN":["通过这种双层检索，你就能得到既包含具体事实，又有整体背景的全面答案。"],"en":["Through this dual-level retrieval, you can get comprehensive answers that include both specific facts and overall context."]}}
---

# Workflow Stage 2: Retrieval Process

## Dual-Level Search in Action

LightRAG uses the knowledge graph for **dual-level retrieval**:

<div v-click="1">

*   **Low-Level Retrieval (Local)**:
    *   Queries specific entities.
    *   Navigates nearby nodes in the graph.
    *   Finds **precise details**.
    *   *Example: Specific stats about electric cars, legal regulations.* 

</div>

<div v-click="2">

*   **High-Level Retrieval (Global)**:
    *   Queries broader concepts.
    *   Explores connections across the **entire graph**.
    *   Identifies **overarching themes**.
    *   *Example: Environmental trends, the future of urban mobility.*

</div>

<div v-click="3">

This provides well-rounded answers with both **facts** and **context**.

</div>

::right::



---
page: 10

layout: two-cols
subtitles: {"default":{"zh_CN":["所以，从我的角度来看，","LightRAG 确实在准确性和速度上比一些老方法有提升。","它能很好地处理新信息，"],"en":["So, from my perspective,","LightRAG indeed offers improvements in accuracy and speed compared to some older methods.","It can handle new information well,"]},"click1":{"zh_CN":["总能给你又新又准、而且非常有上下文感知能力的答案。","这让它在很多场景下都非常有用，比如：","聊天机器人、个人助理，以及需要实时更新信息的搜索工具等。"],"en":["always providing answers that are fresh, accurate, and highly context-aware.","This makes it very useful in many scenarios, such as:","chatbots, personal assistants, and search tools that require real-time information updates, etc."]},"click2":{"zh_CN":["如幻灯片上图表所示，是 LightRAG 的一个评估截图。"],"en":["As shown in the chart on the slide, here is an evaluation screenshot of LightRAG."]},"click3":{"zh_CN":[],"en":[]}}
---

# Why LightRAG Matters

## Improved Performance and Applications

<div v-click="1">

*   **Accuracy & Speed**: Tests show significant improvement over older RAG models.
*   **Handles New Information Gracefully**: Due to incremental updates.

</div>

<div v-click="2">

*   Provides **up-to-date** and **context-aware** answers.

This makes it ideal for applications where quick, relevant responses are key:

*   Chatbots
*   Personal Assistants
*   Dynamic Search Tools

</div>

<div v-click="3">

![Screenshot of Evaluation](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)

*   *As shown in the workflow diagram...*

</div>

::right::



---
page: 11

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["接下来，咱们讲讲怎么在本地搭建 LightRAG。","这里提供了详细的步骤指引。"],"en":["Next, let's talk about how to set up LightRAG locally.","Here is a detailed step-by-step guide."]}}
---

# How to Set Up LightRAG Locally

## A Step-by-Step Guide

Let's walk through how you can get LightRAG running on your machine, first using OpenAI models, then with free/private models like Ollama.

---
page: 12

layout: two-cols
subtitles: {"default":{"zh_CN":["第一步，获取 LightRAG 的代码。","你可以选择从 GitHub 克隆仓库，"],"en":["Step one, get the LightRAG code.","You can choose to clone the repository from GitHub,"]},"click1":{"zh_CN":["或者直接通过 pip 从 PyPI 安装。"],"en":["or directly install from PyPI using pip."]},"click2":{"zh_CN":[],"en":[]}}
---

# Setup Step 1: Get the Code

## Clone the Repository or Install via PyPI

Choose one method to get the LightRAG code:

**Option 1: Clone from GitHub**

<div v-click="1">

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
```

</div>

**Option 2: Install from PyPI**


::right::


<div v-click="2">

```bash
pip install lightrag-hku
```

</div>

---
page: 13

layout: two-cols
subtitles: {"default":{"zh_CN":["第二步和第三步，设置虚拟环境并安装依赖。","建议使用 conda 或 virtualenv 来隔离项目环境。"],"en":["Steps two and three, set up a virtual environment and install dependencies.","It is recommended to use conda or virtualenv to isolate the project environment."]},"click1":{"zh_CN":["然后安装所需的软件包。"],"en":["Then install the required packages."]},"click2":{"zh_CN":[],"en":[]}}
---

# Setup Step 2 & 3: Environment and Dependencies

## Isolate Project and Install Packages

**Step 2: Set Up a Virtual Environment**

Using `conda` or `virtualenv` is recommended to manage dependencies:

<div v-click="1">

```bash
conda create -n lightrag python=3.12
conda activate lightrag
```

</div>

**Step 3: Install Dependencies**

Install the required packages:


::right::


<div v-click="2">

```bash
pip install -e .
```
*   *(If cloning, run this in the cloned directory)*

</div>

---
page: 14

layout: two-cols
subtitles: {"default":{"zh_CN":["第四步，使用 OpenAI 模型来进行索引和查询。","我们将用《圣诞颂歌》作为示例文本。"],"en":["Step four, use OpenAI models to perform indexing and querying.","We will use \"A Christmas Carol\" as the sample text."]},"click1":{"zh_CN":["关于这段代码，首先导入必要的库，设置工作目录，并处理 Jupyter notebook 中的异步问题。"],"en":["Regarding this code snippet, first import the necessary libraries, set the working directory, and handle asynchronous issues in Jupyter notebooks."]}}
---

# Setup Step 4: Index & Run Queries (OpenAI)

## Using GPT Models

Let's index and query sample data using OpenAI models (`gpt-4o-mini-complete` or `gpt-4o-complete`).

We will use "A Christmas Carol" by Charles Dickens as the demo text.

<div v-click="1">

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

#########
# Uncomment the below two lines if running in a jupyter notebook to handle the async nature of rag.insert()
# import nest_asyncio 
# nest_asyncio.apply() 
#########

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)
```
*   *See this code snippet...*

</div>

::right::



---
page: 15

layout: two-cols
subtitles: {"default":{"zh_CN":["接下来，初始化 LightRAG 实例，并指定要使用的语言模型。"],"en":["Next, initialize a LightRAG instance and specify the language model to use."]},"click1":{"zh_CN":["然后，打开文本文件，将内容插入到 LightRAG 中进行索引。","紧接着，我们可以执行一个基本的“naive”模式的查询。"],"en":["Then, open the text file and insert the content into LightRAG for indexing.","Immediately after, we can perform a basic 'naive' mode query."]}}
---

# Setup Step 4: Index & Run Queries (OpenAI) Cont.

## Initializing LightRAG and Indexing Data

Initialize LightRAG, specifying the working directory and the LLM function to use. Then, insert the document content.

<div v-click="1">

```python
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini_complete LLM model
    # llm_model_func=gpt_4o_complete  # Optionally, use a stronger model
)

with open("./book.txt") as f:
    rag.insert(f.read())

# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))
```
*   *Continuing the code...*

</div>

::right::



---
page: 16

layout: two-cols
subtitles: {"default":{"zh_CN":["现在，我们可以尝试使用 LightRAG 的不同检索模式进行查询。","包括本地搜索、全局搜索和混合搜索。"],"en":["Now, we can try querying using LightRAG's different retrieval modes.","Including local search, global search, and hybrid search."]},"click1":{"zh_CN":["这里解释一下这几种模式：","naive 是标准的 RAG 模式。","local 是基于实体邻域的检索，侧重精确细节。","global 是基于更广泛的实体关系，侧重全局上下文。","hybrid 模式则结合了本地和全局检索。"],"en":["Here is an explanation of these modes:","naive is the standard RAG mode.","local is retrieval based on entity neighborhood, focusing on precise details.","global is based on broader entity relationships, focusing on global context.","hybrid mode combines both local and global retrieval."]},"click2":{"zh_CN":[],"en":[]}}
---

# Setup Step 4: Index & Run Queries (OpenAI) Cont.

## Querying with Different Retrieval Modes

Perform queries using the different retrieval modes LightRAG offers:

<div v-click="1">

```python
# Perform local search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))

# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))

# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```

</div>

<div v-click="2">

**Query Modes:**

*   `naive`: Standard RAG
*   `local`: Entity neighborhood-based retrieval (precise)
*   `global`: Broader, global entity relationships retrieval (contextual)
*   `hybrid`: Combines both local and global modes

</div>

::right::



---
page: 17

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["当然，如果你不想用付费的 OpenAI 模型，","或者想在本地运行，也可以使用免费或私有模型。","比如，可以通过 Ollama 来实现，只需要在初始化时配置一下语言模型和嵌入函数即可。"],"en":["Of course, if you don't want to use paid OpenAI models,","or want to run locally, you can also use free or private models.","For example, you can achieve this through Ollama, you just need to configure the language model and embedding function during initialization."]}}
---

# Setup with Free and Private Models

## Using Ollama

You can also use local or private models, such as those available via Ollama, by configuring the `llm_model_func` and `embedding_func`.

---
page: 18

layout: two-cols
subtitles: {"default":{"zh_CN":["大家看一下这段代码，展示了如何使用 Ollama 来搭建 LightRAG。","同样是导入必要的库，设置工作目录。"],"en":["Take a look at this code snippet, which demonstrates how to set up LightRAG using Ollama.","Similarly, import the necessary libraries and set the working directory."]},"click1":{"zh_CN":["关键在于初始化 LightRAG 时，指定 `llm_model_func` 为 `ollama_model_complete`，并且配置 `embedding_func` 来使用 Ollama 的嵌入模型。"],"en":["The key is to specify `llm_model_func` as `ollama_model_complete` during LightRAG initialization, and configure `embedding_func` to use Ollama's embedding model."]}}
---

# Setup with Free and Private Models (Ollama) Cont.

## Code Example (Part 1)

This code shows how to set up LightRAG to use Ollama for both language modeling and embeddings:

<div v-click="1">

```python
import os

from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)
```
*   *Here is the code for using Ollama...*

</div>

::right::



---
page: 19

layout: two-cols
subtitles: {"default":{"zh_CN":["配置好之后，数据的索引和不同模式的查询就和使用 OpenAI 模型时一样了。"],"en":["After configuration, the process for indexing data and querying with different modes is the same as when using OpenAI models."]},"click1":{"zh_CN":["打开文件，插入数据进行索引。","然后分别执行 naive, local, global, hybrid 四种模式的查询。","代码就是这样，非常直观。"],"en":["Open the file and insert the data for indexing.","Then execute naive, local, global, and hybrid queries respectively.","The code is like this, very intuitive."]}}
---

# Setup with Free and Private Models (Ollama) Cont.

## Indexing Data and Running Queries

After initialization, the process for indexing data and running queries with different modes is the same as with OpenAI models:

<div v-click="1">

```python
with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)

# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
)

# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)

# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```
*   *And here's how you index and query with Ollama...*

</div>

::right::



---
page: 20

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 在处理复杂文档或需要进行实体分析的领域尤其有用。","比如在法律研究领域，它可以帮助你理清法律条文、案例和判例之间的关系。"],"en":["LightRAG is particularly useful in fields dealing with complex documents or requiring entity-based analysis.","For example, in legal research, it can help you clarify the relationships between laws, cases, and precedents."]},"click1":{"zh_CN":["在医疗健康领域，可以分析病人的数据，找出症状和治疗方案之间的联系，发现新的医学洞察。","在农业领域，则可以帮助你管理和检索关于作物、土壤、天气等信息，辅助决策。"],"en":["In healthcare, it can analyze patient data, find connections between symptoms and treatments, and uncover new medical insights.","In agriculture, it can help you manage and retrieve information about crops, soil, weather, etc., to assist decision-making."]}}
---

# Key Use Cases for LightRAG

## Applications for Complex Documents

LightRAG is particularly useful in industries dealing with complex documents and requiring entity-based analysis:

<div v-click="1">

1.  **Legal Research**: Extract relationships between laws, cases, and precedents.
2.  **Healthcare**: Analyze patient data, symptoms, and treatments to uncover medical insights.
3.  **Agriculture**: Organize and retrieve information about crops, soil types, and weather patterns.

</div>

---
page: 21

layout: two-cols
subtitles: {"default":{"zh_CN":["如果你手里有很多复杂的文档需要处理，","或者你需要一个能提供既详细又有大局观、而且成本可控的问答系统，","LightRAG 确实提供了一个强大、而且开源的解决方案。","它把知识图谱和向量检索结合起来，"],"en":["If you have a lot of complex documents to process,","or you need a question-answering system that can provide both detailed and big-picture insights, and is cost-controllable,","LightRAG indeed offers a powerful and open-source solution.","It combines knowledge graph and vector retrieval,"]},"click1":{"zh_CN":["再加上增量更新和双层检索这些特性，可以说是 RAG 技术的“下一代”形态了。","而且它的上手也不算复杂，代码仓库里提供了详细的步骤，","不管是接 OpenAI 模型还是本地的 Ollama 模型，看起来都挺直接的。"],"en":["Coupled with features like incremental updates and dual-level retrieval, it can be said to be the 'next generation' form of RAG technology.","Moreover, getting started is not complicated, the code repository provides detailed steps,","whether connecting to OpenAI models or local Ollama models, it looks quite straightforward."]},"click2":{"zh_CN":[],"en":[]}}
---

# Conclusion: Why Choose LightRAG?

## The Next Step in RAG

LightRAG is a powerful, open-source solution that combines:

<div v-click="1">

*   **Knowledge Graph Integration**
*   **Vector-Based Retrieval**

With key features like:

*   **Incremental Updates**
*   **Dual-Level Retrieval**
*   Support for local/smaller models (cost-effective)

</div>

<div v-click="2">

It offers improved practicality and cost-effectiveness compared to GraphRAG.

</div>

::right::



---
page: 22

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["总之，我觉得 LightRAG 是一个值得关注和尝试的技术。","它让我们可以更智能地与海量信息互动，","而且门槛并不像想象中那么高。"],"en":["In summary, I think LightRAG is a technology worth paying attention to and trying.","It allows us to interact with massive amounts of information more intelligently,","and the barrier to entry is not as high as one might imagine."]},"click1":{"zh_CN":["听了我说的这些，你觉得 LightRAG 的哪个特性最吸引你？","或者说，你面临的信息处理难题，它有可能帮你解决吗？"],"en":["Having heard what I've said, which feature of LightRAG is most appealing to you?","Or, can it possibly help solve the information processing challenges you face?"]},"click2":{"zh_CN":["谢谢你的时间！"],"en":["Thank you for your time!"]}}
---

# Final Thoughts

## Experience Next-Gen RAG

LightRAG allows for more intelligent interaction with vast amounts of information, with a lower barrier to entry.

<div v-click="1">

Consider giving it a try today!

*   What feature of LightRAG is most appealing to you?
*   Could it help solve your information processing challenges?

</div>

<div v-click="2">

Thank you!

</div>