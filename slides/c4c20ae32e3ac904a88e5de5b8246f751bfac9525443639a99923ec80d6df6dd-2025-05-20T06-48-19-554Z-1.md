---
page: 1

theme: seriph
background: https://cover.sli.dev
title: "LightRAG: 一种更智能、更经济的 RAG 框架"
titleTemplate: '%s - Slaide'
layout: cover
addons:
  - slidev-theme-viplay
subtitlesConfig:
  noTTSDelay: 2000
  ttsApi: "https://edgetts.deno.dev/v1/audio/speech"
  ttsLangName:
    en: "English(US)"
    zh_CN: "中文(简体)"
  apiCustom:
    voice: 'rate:-0.2|pitch:0.1'
  ttsModel:
    zh_CN:
      - value: "zh-CN-YunjianNeural"
        display: "云间"
      - value: "zh-CN-XiaoxiaoNeural"
        display: "晓晓"
    en:
      - value: "en-US-AndrewNeural"
        display: "Andrew"
      - value: "en-US-AriaNeural"
        display: "Aria"
subtitles: {"default":{"zh_CN":["哈喽大家好！","很高兴今天能跟大家聊聊","一个我觉得特别有意思、也特别重要的东西","—— LightRAG。"],"en":["Hello everyone!","I'm excited to talk to you today about","something I find really interesting and important","— LightRAG."]}}
---

# LightRAG: 下一代 RAG 框架

一种更智能、更经济的检索增强生成方案



---
page: 2

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你想想啊，我们现在跟大语言模型（LLM）打交道，","经常需要它们去理解和利用外部的信息，","也就是所谓的 RAG","(Retrieval-Augmented Generation)，","让模型不只靠自己脑子里的知识，","还能去查资料。","传统 RAG 通常的做法就是把文档切成小块（chunk），","然后模型根据你的问题去找最相关的那些小块来回答。","但问题是，这样切碎了，","文档里那些概念、想法之间原本的关联可能就丢了，对吧？","就像你看一本书，只看零散的句子，","很难理解整个故事线。"],"en":["Think about this: when we interact with large language models (LLMs),","we often need them to understand and utilize external information,","which is known as RAG","(Retrieval-Augmented Generation).","It allows the model to look up information instead of relying only on its internal knowledge.","The traditional approach for RAG is to split documents into isolated text blocks (chunks),","and then the model finds the most relevant chunks based on your query to answer.","But the problem is, by chopping it up like this,","the original contextual relationships between concepts and ideas in the document can be lost, right?","It's like reading a book by only looking at scattered sentences,","making it difficult to understand the overall storyline."]}}
---

# RAG 的挑战：上下文丢失

- **Retrieval-Augmented Generation (RAG)**:
  结合 LLM 和外部数据
- **传统方法**: 将文档分割成孤立的文本块 (chunks)
- **问题**: 忽略了文本块之间的**上下文关系**，难以处理复杂问题和跨块信息



---
page: 3

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["嗯，就是说，我设计 LightRAG 的时候，","就是想解决这个问题。","它是一个更进阶、也更划算的 RAG 框架。","它不光是切块，更关键的是，","它会去理解和构建文档里的实体-关系对。","你就可以把这理解成，","它在文档里画了一张复杂的“关系图”，","把关键的概念（实体）","以及它们之间是怎么连起来的（关系）都标出来。"],"en":["Well, that's why I designed LightRAG,","to solve this specific problem.","It's a more advanced and cost-effective RAG framework.","It doesn't just split documents into chunks; more importantly,","it understands and builds entity-relationship pairs within the documents.","You can think of it as drawing a complex 'relationship map' within the document,","marking the key concepts (entities)","and how they are connected to each other (relationships)."]}}
---

# 什么是 LightRAG？

- 一种先进、高性价比的 RAG 框架
- **核心**: 结合**知识图谱**和**向量检索**
- **创新点**: 构建**实体-关系对**，维护文档内容的上下文关系



---
page: 4

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["你可能听说过微软的 GraphRAG，思路有点像，","也是用图。"],"en":["You might have heard of Microsoft's GraphRAG, which has a similar approach,","also using graphs."]},"click1":{"zh_CN":["但我觉得 LightRAG 有自己非常独特的优势。","简单来说，我打造 LightRAG 就是奔着更快、更便宜、更灵活去的。"],"en":["But I believe LightRAG has its own unique advantages.","Simply put, I built LightRAG to be faster, cheaper, and more flexible."]}}
---

# LightRAG vs. GraphRAG

- **GraphRAG**: 微软提出的基于图的方法，思路相似

<div v-click="1">

- **LightRAG 的优势**: 设计目标是
  - **更快**
  - **更经济**
  - **更灵活**

</div>


---
page: 5

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["具体灵活在哪儿呢？","传统 GraphRAG，嗯，根据我自己的了解，它其实挺“重”的，","跑起来需要很多 API 调用，","有时还得用比较贵的模型，比如 GPT-4o。","而且，如果你想更新数据，比如加点新文档，","它可能需要把整个图重新建一遍，这个成本就上去了。"],"en":["Where exactly is it more flexible?","Traditional GraphRAG, based on my understanding, is quite 'heavy'.","Running it requires many API calls,","and sometimes it needs more expensive models like GPT-4o.","Furthermore, if you want to update data, like adding new documents,","it might require rebuilding the entire graph, which increases costs."]}}
---

# GraphRAG 的局限性

- **资源密集**: 需要大量的 API 调用
- **成本较高**: 常使用 GPT-4o 等昂贵模型
- **更新繁琐**: 数据更新需要**重建整个图谱**



---
page: 6

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["LightRAG 在这方面做了优化："],"en":["LightRAG optimizes in this regard:"]},"click1":{"zh_CN":["1. 它可以用更少的 API 调用，","甚至能用一些更轻量、更便宜的模型，比如 GPT-4-mini。"],"en":["1. It uses fewer API calls,","and can even utilize some lighter, cheaper models like GPT-4-mini."]},"click2":{"zh_CN":["2. 它支持增量更新！","这意味着你有了新信息，不用把整个知识图谱推倒重来，","可以直接把新数据加进去，图谱会相应地更新。","这在信息变化非常快的领域（比如科技新闻、金融数据），","绝对是个巨大的加分项，","能让你的问答系统始终保持最新。"],"en":["2. It supports incremental updates!","This means if you have new information, you don't need to rebuild the entire knowledge graph from scratch;","you can simply add the new data directly, and the graph will update accordingly.","This is a huge advantage in fields where information changes rapidly (like tech news or financial data),","ensuring your Q&A system always stays current."]},"click3":{"zh_CN":["3. 还有一个很酷的功能，","我称之为双层检索（Dual-Level Retrieval）。"],"en":["3. There's another cool feature,","which I call Dual-Level Retrieval."]}}
---

# LightRAG 的优势详情

<div v-click="1">

- **成本控制**: 使用更少的 API 调用，支持 GPT-4-mini 等轻量模型

</div>

<div v-click="2">

- **增量更新**: 无需重建整个图谱，新数据可直接添加，保持信息实时性

</div>

<div v-click="3">

- **双层检索 (Dual-Level)**: 结合局部与全局视角，提升回答质量

</div>


---
page: 7

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["来说说这个双层检索是怎么回事。","整个 LightRAG 的工作流程其实分两步：","构建知识（Indexing）和检索（Retrieval）。"],"en":["Let's talk about how this Dual-Level Retrieval works.","The overall workflow of LightRAG is divided into two main steps:","Building Knowledge (Indexing) and Retrieval."]}}
---

# LightRAG 工作流程概览

**双层检索 (Dual-Level Retrieval)**

整个流程分为两个主要阶段：
1. **索引 (Indexing)**: 构建知识图谱
2. **检索 (Retrieval)**: 基于图谱进行双层查询



---
page: 8

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["第一步，构建知识："],"en":["Step one, building knowledge:"]},"click1":{"zh_CN":["先把你的文档切块。"],"en":["First, split your document into chunks."]},"click2":{"zh_CN":["然后用语言模型识别出每个块里的实体，","比如人名、地名、关键概念。"],"en":["Then, use a language model to identify entities within each chunk,","such as names, places, or key concepts."]},"click3":{"zh_CN":["接着，模型会找出这些实体之间的关系，","形成前面提到的“实体-关系对”。"],"en":["Next, the model identifies the relationships between these entities,","forming the 'entity-relationship pairs' mentioned earlier."]},"click4":{"zh_CN":["这些关系对会被整合成一个知识图谱。","构建过程中，重复的节点啊、多余的关系啊，","我都会尽量去掉，让图谱更精炼。"],"en":["These relationship pairs are then combined into a knowledge graph.","During construction, redundant nodes or unnecessary relationships","are removed as much as possible to make the graph more streamlined."]},"click5":{"zh_CN":["最后，我会把这些实体和关系的描述向量化，","存到一个向量数据库里去，比如 LightRAG 默认用的 Nano Vector。"],"en":["Finally, the descriptions of these entities and relationships are vectorized,","and stored in a vector database, such as Nano Vector, which LightRAG uses by default."]}}
---

# 流程第一步：索引 (Indexing)

构建知识图谱的过程：

<div v-click="1">

1.  **分块 (Chunking)**: 文档分割成小块

</div>

<div v-click="2">

2.  **实体识别 (Entity Recognition)**: LLM 识别实体

</div>

<div v-click="3">

3.  **关系提取 (Relationship Extraction)**: 生成实体-关系对

</div>

<div v-click="4">

4.  **图谱构建 (Graph Construction)**: 组合关系对，优化图谱

</div>

<div v-click="5">

5.  **嵌入存储 (Embedding Storage)**: 实体/关系嵌入向量并存入向量数据库 (如 Nano Vector)

</div>

![LightRAG Indexing Workflow](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*tFELOfFZOKM91xyp)



---
page: 9

layout: image-left
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["第二步，检索，也就是你问问题的时候：","LightRAG 会启动双层检索。"],"en":["Step two, Retrieval, which is when you ask a question:","LightRAG initiates Dual-Level Retrieval."]},"click1":{"zh_CN":["低层检索（Local Level）：","它会重点关注那些跟你的问题最相关的实体的“邻居”，","也就是紧密连接的那些关系和实体。","这就像拿着放大镜看局部，","特别适合回答那些需要精确细节的问题，","比如“某个法规对特定情况有什么影响？”","或者“某种作物今年的产量具体是多少？”"],"en":["Local Level Retrieval:","It focuses on the 'neighbors' of the entities most relevant to your query,","meaning the closely connected nodes and relationships.","This is like using a magnifying glass to look at a specific area,","especially suitable for answering questions requiring precise details,","such as 'What is the impact of a specific regulation on a particular situation?'","or 'What is the exact yield of a certain crop this year?'"]}}
---

# 流程第二步：检索 (Retrieval)

**双层检索：低层 (Local Level)**

<div v-click="1">

- **关注焦点**: 与查询相关的实体的“邻居”（紧密关联的节点和关系）
- **适用场景**: 回答需要**精确细节**的问题
- **示例**: 特定法规影响、作物具体产量等

</div>


---
page: 10

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["高层检索（Global Level）："],"en":["Global Level Retrieval:"]},"click1":{"zh_CN":["它会看整个图谱，找出那些更宏观的主题","和跨越很多实体的大关系。","这就像爬到高处看全景，","能帮你理解更广阔的背景和趋势，","比如“某个行业未来的发展方向是什么？”","或者“气候变化对农业有哪些整体影响？”"],"en":["It looks at the entire graph, identifying more macroscopic themes","and broad relationships spanning across many entities.","This is like climbing high to see the full picture,","helping you understand the broader context and trends,","such as 'What is the future development direction of a certain industry?'","or 'What are the overall impacts of climate change on agriculture?'"]},"click2":{"zh_CN":["通过把这两种检索方式结合起来（也就是它的 \"hybrid\" 模式），","LightRAG 给你的答案就能做到既有具体的细节，","又有更全面的背景和联系，","让回复更立体、更有深度。"],"en":["By combining these two retrieval methods (which is its \"hybrid\" mode),","LightRAG's answers can provide both specific details","and a more comprehensive context and connections,","making the responses more nuanced and in-depth."]}}
---

# 流程第二步：检索 (Retrieval)

**双层检索：高层 (Global Level)**

<div v-click="1">

- **关注焦点**: 整个图谱中的宏观主题和跨实体关系
- **适用场景**: 理解更广阔的背景和**趋势**
- **示例**: 行业发展方向、气候变化对农业的整体影响等

</div>

<div v-click="2">

**Hybrid 模式**: 结合 Local 和 Global，提供既有细节又有全局观的回答。

</div>


---
page: 11

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["那怎么把 LightRAG 用起来呢？","其实挺简单的。"],"en":["So, how do you get started with LightRAG?","It's actually quite simple."]},"click1":{"zh_CN":["你可以直接从 GitHub 上把代码库克隆下来，或者通过 pip 安装。","整个部署主要分四步：","克隆或安装、设置虚拟环境、安装依赖、然后就可以索引数据和运行查询了。"],"en":["You can clone the repository directly from GitHub or install it via pip.","The deployment is mainly in four steps:","Clone or install, set up a virtual environment, install dependencies, and then you can index data and run queries."]},"click2":{"zh_CN":["它支持用 OpenAI 的模型，","也有代码示例教你怎么用 ollama 这样的免费或私有模型，","比如 nomic-embed-text 来处理向量化，","给了你很大的灵活性。","你可以试试不同的查询模式（naive 就是标准 RAG，local、global、hybrid 对应我说的几种图谱检索方式），","看看效果有什么区别。"],"en":["It supports using OpenAI models,","and there are also code examples showing you how to use free or private models like ollama,","such as nomic-embed-text for vectorization,","giving you great flexibility.","You can try different query modes (naive is standard RAG, local, global, hybrid correspond to the graph retrieval methods I mentioned)","to see the difference in results."]}}
---

# 如何本地搭建 LightRAG？

<div v-click="1">

部署步骤概览：

1.  克隆代码库 / Pip 安装
2.  设置虚拟环境
3.  安装依赖
4.  索引数据并运行查询

</div>

<div v-click="2">

支持 OpenAI 或 Ollama (免费/私有) 模型。

</div>


---
page: 12

layout: two-cols
subtitles: {"default":{"zh_CN":[],"en":[]}}
---

# 搭建 LightRAG (步骤 1-3)

**步骤 1: 克隆代码库或 Pip 安装**

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
# Or Install from PyPI
pip install lightrag-hku
```

**步骤 2: 设置虚拟环境 (推荐 Conda/Virtualenv)**


::right::


```bash
conda create -n lightrag python=3.12
conda activate lightrag
```

**步骤 3: 安装依赖**

```bash
pip install -e .
```



---
page: 13

layout: two-cols
subtitles: {"default":{"zh_CN":[],"en":[]}}
---

# 搭建 LightRAG (步骤 4 - OpenAI 模型)

使用 `gpt_4o_mini_complete` 进行索引和查询：

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

# WORKING_DIR = "./dickens"
# ... setup working_dir ...

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=gpt_4o_mini_complete  # Use gpt_4o_mini
    # llm_model_func=gpt_4o_complete  # Optional: stronger model


::right::

)

# with open("./book.txt") as f:
#     rag.insert(f.read())

# Perform naive search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="naive")))
# Perform local search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="local")))
# Perform global search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="global")))
# Perform hybrid search
print(rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid")))
```



---
page: 14

layout: two-cols
subtitles: {"default":{"zh_CN":[],"en":[]}}
---

# 搭建 LightRAG (步骤 4 - Ollama 模型)

使用 `ollama_model_complete` 和 `ollama_embedding` 进行索引和查询：

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc

# WORKING_DIR = "./dickens"
# ... setup working_dir ...

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="your_model_name",
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(texts, embed_model="nomic-embed-text"),
    ),
)


::right::


# with open("./book.txt", "r", encoding="utf-8") as f:
#     rag.insert(f.read())

# Perform naive search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
)
# Perform local search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
)
# Perform global search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
)
# Perform hybrid search
print(
    rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
)
```



---
page: 15

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":[],"en":[]},"click1":{"zh_CN":["LightRAG 提供了几种不同的查询模式。","Naive 模式就是标准的 RAG 模式，不使用图谱的特殊能力。","Local 模式基于实体的局部邻域进行检索，适合找细节。","Global 模式基于图谱的全局关系检索，适合看大局。","Hybrid 模式结合了 Local 和 Global，提供更全面的回答。","你可以根据你的问题类型选择合适的模式来获取最佳回答。"],"en":["LightRAG offers several different query modes.","Naive mode is the standard RAG approach, without using the graph's special capabilities.","Local mode retrieves based on the local neighborhood of entities, suitable for finding details.","Global mode retrieves based on the global relationships in the graph, suitable for seeing the big picture.","Hybrid mode combines Local and Global for more comprehensive answers.","You can choose the appropriate mode based on your question type to get the best answer."]}}
---

# LightRAG 查询模式 (Query Modes)

<div v-click="1">

- **naive**: 标准 RAG 模式
- **local**: 基于实体的局部邻域检索
- **global**: 基于图谱的全局关系检索
- **hybrid**: 结合 local 和 global 模式的混合检索

选择合适的模式获取最佳回答。

</div>


---
page: 16

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["正是因为这种能理解关系、成本可控、更新灵活的特性，","LightRAG 在处理复杂文档和需要基于实体进行深入分析的场景下特别有用。"],"en":["Precisely because of its ability to understand relationships, controllable cost, and flexible updating,","LightRAG is particularly useful in scenarios involving complex documents and needing in-depth analysis based on entities."]},"click1":{"zh_CN":["比如：","在法律研究里，","可以帮你理清法律条文、案例、判例之间的复杂关联。"],"en":["For example:","In legal research,","it can help you untangle the complex connections between statutes, cases, and precedents."]},"click2":{"zh_CN":["在医疗健康领域，","能帮助分析病人数据、症状、治疗方案，找到潜在的医疗洞察。"],"en":["In the healthcare sector,","it can help analyze patient data, symptoms, and treatment plans to uncover potential medical insights."]},"click3":{"zh_CN":["在农业方面，","可以用来组织和检索关于作物、土壤类型、天气模式等等信息，","帮助做决策。"],"en":["In agriculture,","it can be used to organize and retrieve information about crops, soil types, weather patterns, etc.,","to aid decision-making."]}}
---

# LightRAG 主要应用场景

特别适用于处理**复杂文档**或需要基于**实体**进行深入分析的行业：

<div v-click="1">

1.  **法律研究**: 提取法律、案例、判例间的关系。

</div>

<div v-click="2">

2.  **医疗健康**: 分析病人数据、症状、治疗方案，发现洞察。

</div>

<div v-click="3">

3.  **农业**: 组织和检索作物、土壤、天气等信息，辅助决策。

</div>


---
page: 17

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["总的来说，我认为 LightRAG 代表了 RAG 技术的一个重要演进方向，"],"en":["In summary, I believe LightRAG represents an important evolutionary direction for RAG technology,"]},"click1":{"zh_CN":["它把知识图谱和向量检索巧妙地结合起来，"],"en":["It cleverly combines knowledge graphs and vector retrieval,"]},"click2":{"zh_CN":["而且做得更加轻量、更实用、成本更低。"],"en":["and does so in a way that is lighter, more practical, and less costly."]},"click3":{"zh_CN":["尤其是它的增量更新和双层检索，","我觉得这两个点让它在处理动态变化的大量数据时，","相比一些传统或已有的方法更有优势。"],"en":["Especially its incremental updates and dual-level retrieval,","I think these two points give it an advantage over some traditional or existing methods","when dealing with large amounts of dynamically changing data."]}}
---

# 结论：为何选择 LightRAG？

<div v-click="1">

- RAG 技术的**重要演进**

</div>

<div v-click="2">

- 巧妙结合**知识图谱**与**向量检索**

</div>

<div v-click="3">

- **轻量、实用、成本更低**

</div>

<div v-click="4">

- **增量更新**和**双层检索**是关键优势

</div>


---
page: 18

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["如图所示，LightRAG 在某些评估测试中","展示出了它的优异性，","性能表现非常不错。"],"en":["As shown in the figure, LightRAG demonstrates its excellence","in certain evaluation tests,","showing very good performance."]}}
---

# 评估结果示例

如下图所示，LightRAG 在某些评估上展示了其优异性。

![Screenshot of Evaluation](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_fMU05vkAa9zmLxj3R4Ibg.png)



---
page: 19

layout: image-right
image: "https://cover.sli.dev"
subtitles: {"default":{"zh_CN":["如果您正在处理大量文档数据，","或者需要您的问答系统能给出既精准又有上下文、有深度的回答，","我觉得 LightRAG 真的非常值得你去了解和尝试一下。","它能帮你体验到一种更“聪明”、更“有结构”的下一代 RAG 是什么感觉。","好啦，今天就分享到这里。","听完这些，你有没有想到，","在你自己的工作或学习中，有哪些场景是需要处理像这样，","实体和关系非常复杂、而且信息还在不断更新的文档的呢？","LightRAG 也许能帮上忙？"],"en":["If you are dealing with large amounts of document data,","or need your Q&A system to provide answers that are accurate, contextual, and in-depth,","I believe LightRAG is truly worth exploring and trying out.","It can help you experience what a more 'intelligent' and 'structured' next-generation RAG feels like.","Alright, that concludes today's sharing.","After hearing this, have you thought about any scenarios in your own work or studies","that require processing documents like this, where entities and relationships are very complex and information is constantly updating?","Perhaps LightRAG could be of help?"]}}
---

# 立即体验下一代 RAG！

如果您正在处理大量文档数据，
需要**精准**且**有上下文**、**有深度**的回答，
**LightRAG** 是一个强大且开源的选择。

探索它如何帮助您的项目！

